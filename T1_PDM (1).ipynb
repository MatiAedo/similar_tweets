{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LMZaN1fsnnwO"
   },
   "source": [
    "# Tarea 1 - IIC2440 \n",
    "\n",
    "### Sof√≠a Escobedo - Mat√≠as Aedo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YO007OACx-Nx"
   },
   "source": [
    "## Librer√≠as"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librer√≠as que ser√°n utilizadas a lo largo de la tarea. Es tambi√©n necesario tener instalado \"datasketch\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jpaxbNsWx96I"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import clear_output\n",
    "from datasketch import MinHashLSH, MinHash"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpJTc8Ruo3L3"
   },
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora cargamos los datos; si ya se tiene el dataset no ser√° necesario descargarlo de dropbox con wget pero se deja la opci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bspb-9Twdbrg",
    "outputId": "5d11675a-1462-4bc9-e5d5-6b1187e38f84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grafo.jpeg',\n",
       " 'similares_1.csv',\n",
       " 'similares_2.csv',\n",
       " 'similar_tweets',\n",
       " 'Syllabus-2023-1',\n",
       " 'T1_PDM (1).ipynb',\n",
       " 'T1_PDM.ipynb',\n",
       " 'tweets_0_70_noRT.pkl',\n",
       " 'tweets_121_x_noRT.pkl',\n",
       " 'tweets_2022_abril_junio.csv',\n",
       " 'tweets_71_120_noRT.pkl',\n",
       " 'tweets_chico.csv',\n",
       " 'tweets_similares_1.csv',\n",
       " 'tweets_similares_2',\n",
       " 'tweets_similares_2.csv',\n",
       " '__.ipynb']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDl0e8S_x8nn",
    "outputId": "8e1caed2-2f3a-44e6-8d8b-4f94246c9397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ya descargado.\n"
     ]
    }
   ],
   "source": [
    "if 'tweets_2022_abril_junio.csv' in os.listdir():\n",
    "    print('Dataset ya descargado.')\n",
    "else:\n",
    "    !wget \"https://www.dropbox.com/s/j4h5v1arnemhbq3/tweets_2022_abril_junio.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llevamos nuestro dataset al DataFrame con el que trabajaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "Jl0JS3T1nkb0",
    "outputId": "829273c4-5518-42d2-9cff-cbcb5c6660d5"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets_2022_abril_junio.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yaDTImbyyXst"
   },
   "source": [
    "## Visualizaci√≥n inicial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos una visualizaci√≥n inicial del dataframe para ver con qu√© estamos trabajando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0OZGmMLIOIUY",
    "outputId": "f72a8cc4-a1ec-4f68-edc7-81d06871c8db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1512186166438637582</td>\n",
       "      <td>2022-04-07 21:50:51 UTC</td>\n",
       "      <td>h0l4d4ni3l4</td>\n",
       "      <td>RT @ValeMirandaCC: Tras casi 50 a√±os del golpe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1512186202367045642</td>\n",
       "      <td>2022-04-07 21:51:00 UTC</td>\n",
       "      <td>Claudio70932894</td>\n",
       "      <td>RT @UTDTrabajoDigno: Ma√±ana jueves a las 18hrs...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1512186287284924418</td>\n",
       "      <td>2022-04-07 21:51:20 UTC</td>\n",
       "      <td>Cesar_A_RR</td>\n",
       "      <td>RT @JaimeGuajardoR: Aqu√≠ est√° el aporte de @te...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1512186335754301446</td>\n",
       "      <td>2022-04-07 21:51:32 UTC</td>\n",
       "      <td>rosmarieher</td>\n",
       "      <td>RT @melnicksergio: la pelotudez no tiene limit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1512186407841767424</td>\n",
       "      <td>2022-04-07 21:51:49 UTC</td>\n",
       "      <td>GQuelluen</td>\n",
       "      <td>RT @BSepulvedaHales: Ante la circulaci√≥n de no...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id               created_at      screen_name   \n",
       "0  1512186166438637582  2022-04-07 21:50:51 UTC      h0l4d4ni3l4  \\\n",
       "1  1512186202367045642  2022-04-07 21:51:00 UTC  Claudio70932894   \n",
       "2  1512186287284924418  2022-04-07 21:51:20 UTC       Cesar_A_RR   \n",
       "3  1512186335754301446  2022-04-07 21:51:32 UTC      rosmarieher   \n",
       "4  1512186407841767424  2022-04-07 21:51:49 UTC        GQuelluen   \n",
       "\n",
       "                                                text  favorite_count   \n",
       "0  RT @ValeMirandaCC: Tras casi 50 a√±os del golpe...               0  \\\n",
       "1  RT @UTDTrabajoDigno: Ma√±ana jueves a las 18hrs...               0   \n",
       "2  RT @JaimeGuajardoR: Aqu√≠ est√° el aporte de @te...               0   \n",
       "3  RT @melnicksergio: la pelotudez no tiene limit...               0   \n",
       "4  RT @BSepulvedaHales: Ante la circulaci√≥n de no...               0   \n",
       "\n",
       "   retweet_count  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambi√©n queremos saber con cu√°ntas filas estamos trabajando en un principio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u0N63D9EyaB7",
    "outputId": "ad891e71-7847-41f1-c51c-8b4cd6d76564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataframe tiene 4594980 filas.\n"
     ]
    }
   ],
   "source": [
    "shape_0 = df.shape\n",
    "print(f\"El dataframe tiene {shape_0[0]} filas.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DgzvlR4JVkgF"
   },
   "source": [
    "## Preprocesamiento y limpieza de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BroM9qOkbal0"
   },
   "source": [
    "Primero buscaremos eliminar filas duplicadas y valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esta acci√≥n se deshizo de 2174 filas. \n",
      "El dataframe tiene 4592806 filas.\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['id', 'text'])\n",
    "df = df.dropna(subset=['id', 'text', 'screen_name'])\n",
    "shape_1 = df.shape\n",
    "print(f\"Esta acci√≥n se deshizo de {shape_0[0] - shape_1[0]} filas. \\nEl dataframe tiene {shape_1[0]} filas.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tampoco nos interesa mantener aquellas filas cuyo \"screen_name\" y \"text\" es el mismo, es decir, un usuario que twitte√≥ dos veces lo mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9BSF-wEnaEq1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esta acci√≥n se deshizo de 42834 filas. \n",
      "El dataframe tiene 4549972 filas.\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['screen_name', 'text'])\n",
    "shape_2 = df.shape\n",
    "print(f\"Esta acci√≥n se deshizo de {shape_1[0] - shape_2[0]} filas. \\nEl dataframe tiene {shape_2[0]} filas.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre los tweets que vimos en la visualizaci√≥n inicial pudimos notar que son todos retweets. Ya que los retweets de una persona no nos dicen nada sobre su propio estilo de escritura, hemos decidido eliminarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esta acci√≥n se deshizo de 3299423 filas. \n",
      "El dataframe tiene 1250549 filas.\n"
     ]
    }
   ],
   "source": [
    "df = df[~df['text'].str.startswith('RT')]\n",
    "shape_3 = df.shape\n",
    "print(f\"Esta acci√≥n se deshizo de {shape_2[0] - shape_3[0]} filas. \\nEl dataframe tiene {shape_3[0]} filas.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tpy8e7NUsTOm"
   },
   "source": [
    "Ahora que terminamos el preprocesamiento de los datos, pasaremos a la limpieza del \"texto\" de los tweets. Usaremos una copia del dataframe para mostrar ciertos ejemplos de la limpieza que se har√° luego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpieza = df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pudimos notar que en lugar de \"&\" se encontraba la presencia de \"&amp\" en los tweets. \n",
    "\n",
    "A continuaci√≥n, mostramos un ejemplo de un tweet en el que esto sucede y c√≥mo quedar√° despu√©s de limpiarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQ7KujnPUnb-",
    "outputId": "9721c0ea-aa95-4805-cc72-a2acaf5c6481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet previo a limpieza:\n",
      " @mcubillossigall &amp; fuiste ministra de educaci√≥n JAJASJAJ ü§°ü§°ü§°ü§°ü§°\n",
      "Tweet posterior a limpieza:\n",
      " @mcubillossigall & fuiste ministra de educaci√≥n JAJASJAJ ü§°ü§°ü§°ü§°ü§°\n"
     ]
    }
   ],
   "source": [
    "ejemplo_1 = df_limpieza.text[4549723]\n",
    "print(\"Tweet previo a limpieza:\\n\", ejemplo_1)\n",
    "ejemplo_1 = BeautifulSoup(ejemplo_1, 'lxml')\n",
    "ejemplo_1 = ejemplo_1.get_text()\n",
    "df_limpieza.at[4549723, 'text'] = ejemplo_1\n",
    "print(\"Tweet posterior a limpieza:\\n\", df_limpieza.text[4549723])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchos de los tweets tienen im√°genes o gifs, la mayor√≠a utilizadas como \"reacciones\" o \"memes\". El mantener esto en el \"texto\" del tweet podr√≠a causar problemas a la hora de encontrar personas similares, ya que no tiene que ver con su estilo de escritura y podr√≠a sezgar los resultados a simplemente personas que utilizaron la misma imagen de reacci√≥n. \n",
    "\n",
    "Por esto, ser√°n eliminados los \"links\" que denotan im√°genes o gifs. A continuaci√≥n, mostramos un ejemplo de un tweet en el que esto sucede y c√≥mo quedar√° despu√©s de limpiarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet previo a limpieza:\n",
      " @christianpviera Taba juerte parece. https://t.co/QvdsK7OeGm\n",
      "Tweet posterior a limpieza:\n",
      " @christianpviera Taba juerte parece. \n"
     ]
    }
   ],
   "source": [
    "ejemplo_2 = df_limpieza.text[4568847]\n",
    "print(\"Tweet previo a limpieza:\\n\", ejemplo_2)\n",
    "ejemplo_2 = re.sub('https?://[A-Za-z0-9./]+','',ejemplo_2)\n",
    "df_limpieza.at[4568847, 'text'] = ejemplo_2\n",
    "print(\"Tweet posterior a limpieza:\\n\", df_limpieza.text[4568847])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar el resto del proceso con la limpieza tal cual est√° hasta el momento, notamos que comenzaba a agrupar los tweets similares seg√∫n las menciones realizadas en un tweet, por lo que cualquier respuesta o menci√≥n a otra persona contaba como una similaridad. Esto sezga los resultados, ya que no encuentra similitudes seg√∫n el estilo de escritura sino seg√∫n a qu√© persona se menciona.\n",
    "\n",
    "Por esto, decidimos eliminar las menciones. A continuaci√≥n, mostramos un ejemplo de un tweet en el que esto sucede y c√≥mo quedar√° despu√©s de limpiarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet previo a limpieza:\n",
      " @HernanLarrain @gabrielboric Que va a hacer nada!! Solo prestarle ropa para que se siga equivocando\n",
      "Tweet posterior a limpieza:\n",
      " Que va a hacer nada!! Solo prestarle ropa para que se siga equivocando\n"
     ]
    }
   ],
   "source": [
    "ejemplo_3 = df_limpieza.text[17]\n",
    "print(\"Tweet previo a limpieza:\\n\", ejemplo_3)\n",
    "ejemplo_3 = ejemplo_3.replace(\"_\", \"\")\n",
    "ejemplo_3 = re.sub(r'@\\w+\\b','', ejemplo_3)\n",
    "ejemplo_3 = ejemplo_3.lstrip()\n",
    "df_limpieza.at[17, 'text'] = ejemplo_3\n",
    "print(\"Tweet posterior a limpieza:\\n\", df_limpieza.text[17])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya se han mostrado ejemplos de la limpieza que ser√° realizada, es momento de realizarla sobre todas las filas del dataframe preprocesado. Para distintas pruebas que se quieren realizar, los tweets ser√°n divididos seg√∫n su largo con los grupos siendo tweets de entre 0 a 70 caracteres, 71 a 120 caracteres y de m√°s de 120 caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 531 ms\n",
      "Wall time: 934 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets_0_70 = {}\n",
    "tweets_71_120 = {}\n",
    "tweets_121_x = {}\n",
    "\n",
    "if 'tweets_0_70_noRT.pkl' in os.listdir():\n",
    "    file = open('tweets_0_70_noRT.pkl', 'rb')\n",
    "    tweets_0_70 = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "    file = open('tweets_71_120_noRT.pkl', 'rb')\n",
    "    tweets_71_120 = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "    file = open('tweets_121_x_noRT.pkl', 'rb')\n",
    "    tweets_121_x = pickle.load(file)\n",
    "    file.close()\n",
    "else:\n",
    "    for index, row in df.iterrows():\n",
    "        texto = row['text']\n",
    "      \n",
    "        if '&amp' in texto:\n",
    "            texto = BeautifulSoup(texto, 'lxml')\n",
    "            texto = texto.get_text()\n",
    "            df.at[index, 'text'] = texto\n",
    "\n",
    "        if 't.co' in texto:\n",
    "            texto = re.sub('https?://[A-Za-z0-9./]+', '', texto)\n",
    "            df.at[index, 'text'] = texto\n",
    "      \n",
    "        if '@' in texto:\n",
    "            texto = texto.replace(\"_\", \"\")\n",
    "            texto = re.sub(r'@\\w+\\b','', texto)\n",
    "            texto = texto.lstrip()\n",
    "            df.at[index, 'text'] = texto\n",
    "        \n",
    "        if len(texto) > 2:\n",
    "            if len(texto) < 71:\n",
    "                tweets_0_70[str(row['id'])] = texto\n",
    "            elif len(texto) < 121:\n",
    "                tweets_71_120[str(row['id'])] = texto\n",
    "            else:\n",
    "                tweets_121_x[str(row['id'])] = texto\n",
    "                \n",
    "    df = df[df['text'].str.len()>2]\n",
    "        \n",
    "    file = open('tweets_0_70_noRT.pkl', 'wb')\n",
    "    pickle.dump(tweets_0_70, file)\n",
    "    file.close()\n",
    "\n",
    "    file = open('tweets_71_120_noRT.pkl', 'wb')\n",
    "    pickle.dump(tweets_71_120, file)\n",
    "    file.close()\n",
    "\n",
    "    file = open('tweets_121_x_noRT.pkl', 'wb')\n",
    "    pickle.dump(tweets_121_x, file)\n",
    "    file.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QshmJU2bltds",
    "outputId": "0b62cd07-ea79-48e9-9dd0-8925ce5d923b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tweets entre 0 y 70 caracteres: 834150\n",
      "Cantidad de tweets entre 71 y 120 caracteres: 276811\n",
      "Cantidad de tweets con m√°s de 120 caracteres: 10684\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cantidad de tweets entre 0 y 70 caracteres: {len(tweets_0_70)}\")\n",
    "print(f\"Cantidad de tweets entre 71 y 120 caracteres: {len(tweets_71_120)}\")\n",
    "print(f\"Cantidad de tweets con m√°s de 120 caracteres: {len(tweets_121_x)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crear√° \"big_tweets\" como uni√≥n de los tres grupos anteriores para el procesamiento de datos con todas las filas juntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tweets total: 1121645\n"
     ]
    }
   ],
   "source": [
    "big_tweets = tweets_0_70 | tweets_71_120 | tweets_121_x\n",
    "\n",
    "print(f\"Cantidad de tweets total: {len(big_tweets)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de comparaci√≥n, hashing y Jaccard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para generar k-shingles a partir de un texto dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_k_shingles(text, k):\n",
    "    shingles = set()\n",
    "    for i in range(len(text) - k + 1):\n",
    "        shingle = text[i:i+k]\n",
    "        shingles.add(shingle)\n",
    "    return shingles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para crear un √≠ndice LSH a partir de un diccionario de textos, utilizando el algoritmo de firma MinHash y el esquema LSH  a las firmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hash_lsh(texts_dict, threshold, k):\n",
    "    lsh = MinHashLSH(threshold=threshold)\n",
    "    count = 0\n",
    "    for text_id, text in texts_dict.items():\n",
    "        shingles = generate_k_shingles(text, k)\n",
    "        minhash = MinHash()\n",
    "\n",
    "        for shingle in shingles:\n",
    "            minhash.update(shingle.encode('utf8'))\n",
    "        \n",
    "        lsh.insert(text_id, minhash)\n",
    "        count += 1\n",
    "        \n",
    "        # descomentar si se quieren \"updates\" \n",
    "        #if count % 5000 == 0:\n",
    "        #    print(\"Se han hasheado \", count, \" tweets\")\n",
    "\n",
    "    return lsh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para buscar en un √≠ndice LSH los elementos que coinciden con un tweet dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_bucket(lsh, tweet, k):\n",
    "    shingles = generate_k_shingles(tweet, k)\n",
    "    minhash_actual = MinHash()\n",
    "    for shingle in shingles:\n",
    "        minhash_actual.update(shingle.encode('utf8'))\n",
    "\n",
    "    result = lsh.query(minhash_actual)\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para calcular el coeficiente de Jaccard entre dos tweets dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(tweet1, tweet2, k):\n",
    "    shingles1 = generate_k_shingles(tweet1, k)\n",
    "    shingles2 = generate_k_shingles(tweet2, k)\n",
    "\n",
    "    result = len(shingles1.intersection(shingles2)) / len(shingles1.union(shingles2))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para buscar tweets similares a uno de referencia utilizando un √≠ndice LSH y el coeficiente de Jaccard. Si se ingresa un \"reference_id\" se buscan para el tweet pedido, y si no se busca un tweet al azar dentro del diccionario text_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_tweets(text_dict, reference_id = False, print_it = False):\n",
    "    if not reference_id:\n",
    "        reference_id, reference_text = random.choice(list(text_dict.items()))\n",
    "    else:\n",
    "        reference_text = text_dict[reference_id]\n",
    "    \n",
    "    # obtener el bucket del tweet con sus tweets similares seg√∫n lsh\n",
    "    bucket = obtain_bucket(lsh, reference_text, k)\n",
    "    \n",
    "    # evaluar su similaridad seg√∫n el coeficiente de Jaccard\n",
    "    tweets_similares = {}\n",
    "    for id in bucket:\n",
    "        similaridad = jaccard(reference_text, text_dict[id], k)\n",
    "        if similaridad > s and reference_id!=id:\n",
    "            tweets_similares[id] = [text_dict[id], similaridad]\n",
    "    \n",
    "    # imprimir los tweets si es requerido\n",
    "    if print_it:\n",
    "        print(f'Buscando tweets similares a \"{reference_text}\"')\n",
    "        i = 1\n",
    "        for key, value in tweets_similares.items():\n",
    "            print(f'{i}. {value[0]}')\n",
    "            i += 1\n",
    "            \n",
    "    return [reference_id, tweets_similares]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para guardar los tweets similares en un csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_to_csv(dictionary, filename):\n",
    "    with open(filename, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['ID', 'Tweet'])  # Escribir el encabezado\n",
    "\n",
    "        for key, value in dictionary.items():\n",
    "            writer.writerow([key, value[0]]) # Escribir cada fila"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para ajustar el diccionario \"usuarios\" seg√∫n tweets similares a un tweet espec√≠fico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_similar_users(df, tweets_similares, usuarios):\n",
    "    for key, value in tweets_similares.items():\n",
    "        user = df.loc[df['id'] == int(key), 'screen_name'].values[0]\n",
    "        if user in usuarios.keys():\n",
    "            cantidad = usuarios[user][1]\n",
    "            new_value = ((usuarios[user][0] * cantidad) + value[1])/(cantidad+1)\n",
    "            usuarios[user] = [new_value, cantidad+1]\n",
    "        else: \n",
    "            usuarios[user] = [value[1], 1]\n",
    "    return usuarios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para truncar la lista de usuarios similares, quedandonos solo con aquellos que tengan m√°s de \"t\" tweets similares y por sobre un \"s\" de similaridad en general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_users(usuarios, s, t):\n",
    "    u_copy = usuarios.copy()\n",
    "    for u in u_copy:\n",
    "        if usuarios[u][0] < s:\n",
    "            del usuarios[u]\n",
    "        elif usuarios[u][1] < t:\n",
    "            del usuarios[u]\n",
    "            \n",
    "    usuarios = {k: v for k, v in sorted(usuarios.items(), key=lambda x: x[1][0], reverse=True)}\n",
    "    return usuarios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para encontrar usuarios similares a uno en espec√≠fico; para hacer esto se buscan todos los tweets de ese usuario y para cada uno sus tweets similares. Con esto se va creando el diccionario \"usuarios\" cuya llave es el nombre del otro usuario y sus valores son la similaridad promedio y la cantidad de tweets similares encontrados. \n",
    "\n",
    "Para finalizar, se truncan los resultados para obtener aquellos usuarios que tengan m√°s de 10 tweets similares (ya que consideramos que menos de eso es inconclusivo) y m√°s de un 0.5 de similaridad (ya que consideramos que menos de eso no es realmente similar). \n",
    "\n",
    "Si no se entrega un usuario, la funci√≥n buscar√° uno al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_users(df, tweets_similares, text_dict, user=False):\n",
    "    if not user:\n",
    "        user = df.sample().values[0][2]\n",
    "    \n",
    "    print(f'Buscando usuarios similares a {user}...')\n",
    "    \n",
    "    user_tweets = df[df['screen_name'] == user]\n",
    "    \n",
    "    i = 1\n",
    "    usuarios = {}\n",
    "    for tweet in user_tweets.values:\n",
    "        print(f'Revisando {i}/{len(user_tweets)} tweets...')\n",
    "        reference_id, tweets_similares = get_similar_tweets(big_tweets, str(tweet[0]))\n",
    "        usuarios = tweet_similar_users(df, tweets_similares, usuarios)\n",
    "        i += 1\n",
    "    \n",
    "    usuarios = most_similar_users(usuarios, 0.5, 10)\n",
    "    \n",
    "    if len(usuarios) == 0:\n",
    "        print('No se lograron encontrar usuarios similares.')\n",
    "    return [user, usuarios]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para imprimir los usuarios similares a un usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_similar_users(usuario, usuarios):\n",
    "    print(f'Los usuarios m√°s similares a {usuario} son')\n",
    "    i = 1\n",
    "    for u in usuarios:\n",
    "        print(f'{i}. {u} con una similaridad de {usuarios[u][0]} para {usuarios[u][1]} tweets.')\n",
    "        i += 1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para imprimir los perfiles de dos usuarios similares encontrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similar_pair(user1, user2):\n",
    "    user1_tweets = df[df['screen_name'] == user1]\n",
    "    user2_tweets = df[df['screen_name'] == user2]\n",
    "    \n",
    "    print(f'Perfil del Usuario {user1}')\n",
    "    for tweet in user1_tweets.values:\n",
    "        print(tweet[3])\n",
    "    \n",
    "    print('- '*30)\n",
    "    \n",
    "    print(f'Perfil del Usuario {user2}')\n",
    "    for tweet in user2_tweets.values:\n",
    "        print(tweet[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el LSH. Se puede probar con distintos k, s y threshold. Esta celda toma entre 20 y 40 minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "s = 0.2\n",
    "threshold = 0.2\n",
    "\n",
    "# Se crea el LSH\n",
    "lsh = create_hash_lsh(big_tweets, threshold, k)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener tweets similares"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n, entregamos dos ejemplos obteniendo tweets similares a uno dado. Primero ser√° con uno que hayamos elegido, y el otro ser√° al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando tweets similares a \"Metete tus normas donde ud sabe\"\n",
      "1. Puro pico tus normas saco wueas\n",
      "2. Ah√≠ tus cagas de norma‚Ä¶‚Ä¶\n",
      "3. Metete tus normas por el orto pajaron qliao\n",
      "4. Metete las normas normas en la raja\n",
      "5. Ninguno, ud no sabe entender las normas\n",
      "6. Una Mier‚Ä¶ tus normas!!! \n",
      "7. Ni si quiera  se sabe las normas.\n",
      "8. Ya sabes donde meterte tus \"buenas noticias\" para ti, con letra chica para el resto.\n",
      "9. Metete tus palabras por donde quieras.\n",
      "10. M√©tete tu apruebo por donde mas te quepa!\n",
      "11. Metete tu solidaridad por donde te quepa\n",
      "12. Metete las C√°psulas por donde ya sabes\n",
      "ü§¶\n",
      "13. De donde sac√≥ ud eso?\n",
      "14. Sabes donde metertetela \n",
      "15. M√©tete tus banderas... tu sabes x donde!\n",
      "16. M√©tete tu borrador por donde tu sabes.\n",
      "17. Metetela donde te caigaüòè\n",
      "18. Metete tu porquer√≠a por donde te quepa\n",
      "19. Este no sabe donde tiene la #raja !!!\n",
      "20. Metete tu CC por donde te quepa!!!!\n",
      "21. Evidentemente no sabes donde est√°s parada\n",
      "22. M√©tete tu constituci√≥n ya sabes por donde\n",
      "23. Metete tu pluri por donde mas te quepa vieja chanta\n",
      "24. Metas las normas donde le quepan...\n",
      "25. Metela ya sabes por donde\n",
      "26. Metetela x donde te quepa ctm\n",
      "27. ü§£ü§£ü§£ü§£ü§£ ya sabes donde meterte la carta \n",
      "28. Metete tu borrador por donde mas te gusteüí©üí©üí©ü§¨ü§¨ü§¨ü§¨ü§¨\n"
     ]
    }
   ],
   "source": [
    "tweets_similares = get_similar_tweets(big_tweets, '1525861915976556550', True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo guardamos en csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_to_csv(tweets_similares[1], 'tweets_similares_1.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos con un tweet generado al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando tweets similares a \"Mentiroso!!! Que genial que hagas esto!, as√≠ se empiezan a desenmascarar a los asquerosos mentiroso\"\n",
      "1. Desenmascarando a los zurdos mentirosos.\n",
      "2. Que vieja asquerosa mas mentirosa! Que asco de ser humano\n",
      "3. Y sigan desenmascarando las mentiras y falsedades de los convencionales que fueron all√° solo a boicotear el proceso!!!\n",
      "4. Bien  as√≠ se interpela a los mentirosos!\n",
      "5. Gracias x desenmascarar a estos mentirosos y mala clase.\n",
      "6. , bien Bernardo a desenmascarar a los zurdos mentirosos\n",
      "7. Qu√© verg√ºenza das Harboe. Empiezan a salir a la luz los mentirosos \n",
      "8. Cuando tergiversas...pero a los minutos, se desenmascaran tus mentiras‚ùó\n",
      "9. M√°s estupidos son quienes les creen a estos mentirosos que se desdicen solos!!!\n",
      "10. As√≠ se desenmascara un mentiroso, incapaz de hilvanar un contrargumento porque no los hay\n",
      "11. En TV abierta para desenmascarar al mentiroso del rechazo\n",
      "12. Siempre atacan a los que los desenmascaran ! Siga y cu√≠dese no mas !\n",
      "13. Que haya que estar desmintiendo a cada rato a estos mentirosos qls.... \n",
      "14. desenmascarando al mentiroso de Atria\n",
      "15. Hay que encarar a estos ones mentirosos el tema es como\n",
      "Talvez una marea de Twitter\n",
      "16. Excelente Tere, a seguir desenmascarando a estos mentirosos y enemigos de la patria...\n",
      "17. Gracias por informar. Hay que seguir desenmascarando a estas lacras mentirosas.\n",
      "18. En TV abierta para desenmascarar al mentiroso del rechazo\n",
      "19. Quiere una lista de los mentirosos de izquierda? Esa s√≠ que es larga, empieza con B.\n",
      "20. El que miente no es Auth, el est√° desenmascarando a los mentirosos de la convencion.\n",
      "21. Paseada, y ojal√° siempre los saquen a pasear para desenmascarar sus mentiras.\n",
      "22. Vieron quienes son los mentirosos ahora??? Gracias Pepe por desenmascarar a los mentiroso de la CC, PC, etc\n",
      "23. Seca la  Gracias ppr desmascarar a estos mentirosos caras de raja.\n",
      "24. Bravo  , as√≠ se hace con los mentirosos.\n",
      "25. Exacto, eso es mentir y tenemos que desenmascarlos por mentirosos.\n",
      "26. As√≠ se desenmascaran las mentiras.\n",
      "27. TV abierta para desenmascarar al mentiroso del rechazo\n",
      "28. P√≠deselo a los mentirosos, igual que t√∫!..\n",
      "29. Ya la gente se est√°n dando cuenta lo mentirosos que son!!!!\n",
      "30. La mejor manera de desenmascarar a los mentirosos en tv es esta,enfrentando de una las mentiras y exponer la verdad.\n",
      "31. Usted vaya a desenmascarar todas las mentiras de estos payasos.\n",
      "32. A desenmascarar a estos mentirosos!!\n",
      "#LaConvencionSeDefiende\n",
      "33. Notable, ojalas pudieran desenmascarar todas esas mentiras que atrae el rechazo.\n",
      "34. Grande  desenmascarando al mentiroso de siempre\n",
      "35. Gracias Barbarita bella por desenmascarar a estos mentirosos.\n",
      "36. Estupendo a desenmascar a esta gente mentirosa Fontaine üëèüëèüëèüëè\n",
      "37. que curioso que siempre lleven a los mentirosos a ese programa\n",
      "38. Ac√° para desenmascarar a la mentirosa\n",
      "\n",
      "39. Gracias  por desenmascaras a estos mentirosos embaucadores. Yo #RechazoEl4deSeptiembre\n",
      "40. Son unos asquerosos mentirosos que nos llevar√°n a la total perdici√≥n.\n",
      "41. O sea tu estas por los mentirosos que no se hacen cargo de sus declaraciones\n",
      "42. Desenmascarando a los mentirosos\n",
      "43. Muy bien, sacar a la Pizarra para desenmascarar a estos derechistas mentirosos.\n",
      "44. Desenmascarando a los mentirosos de la CC. üëèüëè\n"
     ]
    }
   ],
   "source": [
    "tweets_similares = get_similar_tweets(big_tweets, print_it=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y lo guardamos en csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_to_csv(tweets_similares[1], 'tweets_similares_2.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener personas similares"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n, entregamos tres ejemplos obteniendo personas similares a un usuario dado. Primero ser√° con uno que hayamos elegido porque tienen estilos de escritura similar, el segundo ser√° uno que elegimos por su contenido similar, y el otro ser√° al azar.\n",
    "\n",
    "Buscamos usuarios similares a \"jnfernandez\" utilizando la funci√≥n ya discutida \"get_similar_users\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "user, users = get_similar_users(df, tweets_similares, big_tweets, 'jnfernandez')\n",
    "clear_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los usuarios m√°s similares a \"jnfernandez\" junto a su similaridad promedio y la cantidad de tweets similares en total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los usuarios m√°s similares a jnfernandez son\n",
      "1. pennaleon con una similaridad de 0.7000000000000001 para 10 tweets.\n",
      "2. Ninoskadamianov con una similaridad de 0.609831029185868 para 16 tweets.\n",
      "3. ChileDemocrata con una similaridad de 0.5951284861770796 para 10 tweets.\n",
      "4. SoyLaIngo con una similaridad de 0.5932539682539683 para 14 tweets.\n",
      "5. 711Diaz con una similaridad de 0.5563687724704675 para 11 tweets.\n",
      "6. santosfreaks con una similaridad de 0.5347939885173927 para 12 tweets.\n",
      "7. Nathalie_lav con una similaridad de 0.5330184435447592 para 10 tweets.\n",
      "8. PatricioOgalde5 con una similaridad de 0.5125000000000001 para 12 tweets.\n"
     ]
    }
   ],
   "source": [
    "print_similar_users(user, users)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos el perfil del usuario con el que partimos y su usuario m√°s \"similar\". Se puede ver que a pesar de que uno es claramente por el rechazo y el otro es del apruebo, los dos son muy agresivos en su estilo de escribir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfil del Usuario jnfernandez\n",
      "Poniendo una chaucha (10%) y te entragan una tasa de reemplazo del 30%. Q m√°s quieres. Pura ignorancia estos.\n",
      "Uno puede seguir el juego, pero nadie espera q hagan una pi√±ata con tu cara para hacerla tira. No sea weon!\n",
      "Y dices: Deja la pasta.  Es no cachar nada.\n",
      "Se entiende lo picante q es el mamarracho.\n",
      "P√≠dele a tu presidente q apoye el 100%  o  a los pasteles de la CC. Veamos si somos o no due√±os... IGNORANTE!\n",
      "Esa es la pelea, lo saben y es tramposo. Ya lo hicieron para la cc.\n",
      "Ya se puso grosera y no entiendes el punto. Dije: gente fresca.\n",
      "Para q dejarlo en manos de pol√≠ticos pencas??? Entiende el punto.\n",
      "Q lamentable. Algo oscuros los atrias. Arica sabe bien de \n",
      "Jajaja le acomodas el pillama? Da lo mismo.\n",
      "Te sali√≥ el cuco.\n",
      "jajajaja date cuenta.\n",
      "Debe ser los tipos m√°s lucidos en esa wea.\n",
      "Copy paste de la venezolana.  Te falt√≥: en justicia.\n",
      "Q lea algo d lo q pasa en el sur y en el norte.\n",
      "Aahh pero para lo que usan pi√±ata con la cara de otros... defiendes. Doble moral, doble discurso. Muy chanta.\n",
      "Jackson  se lo auto dona y lo publica...\n",
      "Farsante!\n",
      "Boric es funcional al PC.\n",
      "Me recuerdan a peter veneno con tantos adjetivos. Di reparto, todos al saco. Y dejen de ser unos farsantes.\n",
      "infelices...\n",
      "Plataforma del profesor q plagia contenidos y es del izq. muy cercano a boric? mmm\n",
      "Q nobleza  jajajaja... Hasta para eso son miserables.\n",
      "Pfff deber√≠as leerte.\n",
      "Q se de una vuelta por fuera de la Muni.\n",
      "Colectivos?\n",
      "Y miente! Q te lo diga lagos y bachelet\n",
      "Las patitas d  , grita como  loco en sus intervenciones si le contradicen algo.\n",
      "Mandantes el procedimiento actual de expropiaci√≥n y sales con eso. Anda leerlo para q no digas barbaridades.\n",
      "Obvio! te vieron la cara...\n",
      "Y no lo van hacer. Est√°n atrapados, validaron la violencia y le tienen miedo a yaitul y el pc.\n",
      "Claramente, dile eso a Mister Encapuchado.\n",
      "Supuesto!!! Ser√° a la conveniencia del estado. Te creo bien poco, lobo con piel de oveja.\n",
      "Plop!\n",
      "Stingo, c√≥rtala, deja de mentir.\n",
      "Puros artistas en ese üé™.\n",
      "Y bastante q las usaste en el pasado. Se esperaba m√°s d t√∫ persona. Un fiasco.\n",
      "Un copy / paste picante...\n",
      "Quiz√°s, ya que la prensa chilena es comparsa de es mamaracho...\n",
      "Rechazo ese mamarracho.\n",
      "\"abusa del conocimiento que dice manejar para manipular a su audiencia\" ES TU TECNICA ATRIA. Pura retorica.\n",
      "Una locura el mamarracho...\n",
      "Espero q gane el rechazo y q t√∫ dejes d vivir a costa del pueblo.\n",
      "Atria sigue sin poder defender el art√≠culo, q es bien malito.\n",
      "bananero, mamag√ºevo todas esos \"t√©rminos\" para el  \n",
      "bananero, mamag√ºevo todos esos \"t√©rminos\" para el  \n",
      "\n",
      "Todo cocinado?\n",
      "Paso 4 si es rechazada por sobre del 60% (acto democr√°tico). Dejar√≠an de quemar?\n",
      "Hablas de stingo?\n",
      "jajajaja como su hubiera una diferencia.\n",
      "Oiga, no se humille...\n",
      "jajaja me encanta t√∫ desesperaci√≥n... espero q alg√∫n d√≠a, dejes de vivir del dinero d todos los Chilenos.\n",
      "Da lo mismo, tal como lo est√°n dejando. Dejaron la puerta abierta para los populistas. Un desastre!\n",
      "La propiedad sigue siendo del estado. Q no entiendes?\n",
      "Y Stingo le pag√≥ a sus trabajadores?\n",
      "Usatedes son la isla de la fantas√≠a...\n",
      "Ahora est√°s leyendo soberbio. Bajaste del ol√≠mpico?\n",
      "Le est√°s picando aj√≠ a los seguidores del mes√≠as üòÇüòÇüòÇ. As√≠ con la hipocres√≠a...\n",
      "Incre√≠ble! tanto odio y fanatismo por ac√°.\n",
      "\"Dej√©monos de hablar wevadas por favor.\" AUTO - APLICALO xfa...\n",
      "Literal... \n",
      "Pero dejarnos m√°s divididos imposible. Y lo lograron. Q bochorno.\n",
      "Pfff... ahora es h√©roe nacional?\n",
      "Trabaja,  solo eso. Cara de palo!\n",
      "Q bueno q sigas pensando webadas. As√≠ se termina de caer el mamarracho.\n",
      "Te entr√≥ el terror comunista?\n",
      "Supongamos q se quieran cambiar los esca√±os reservados o los privilegios sobre los recursos naturales?\n",
      "Te gusta la chanchada... s√∫per digno.\n",
      "El estado...\n",
      "jajajajajajaja\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Perfil del Usuario pennaleon\n",
      "Loca!!!! Que manera de mentir, el perder los desquicio.\n",
      "Que se junte con la Daza, y la Mathei para la gira , no convocan ni a un gato. Se tiene fe la  jajajajajaja\n",
      "En septiembre llega la primavera, y florecen con fuerza, adem√°s somos arboles perennes, jajajajajajajajaüå≤üå≤üå≤üå≤üå≤üå≤üå≤\n",
      "Esta es la Derecha admiradora de la Cubillos y Pi√±era.\n",
      "Entonces en vez de andar criticando trabaj√©!\n",
      "No tiene nada de malo, a qu√© le tiene miedo usted.\n",
      "Apoyo\n",
      "Lo hizo muy bien, clara en su exposici√≥n üëèüëèüëèüëèüëè\n",
      "Jajajajajaja no pod√≠a faltar el comentario de Felipin\n",
      "jajajajajajajaja\n",
      "No lo hab√≠a gracias lo voy a difundir.\n",
      "Pat√©tico es desinformar y mentir. Aplaudo esta informaci√≥n\n",
      "Delirante\n",
      "Tanto te cuesta entender c√≥mo opera la Democracia. Y... quien es la centro izquierda?\n",
      "Sin poder judicial? Tenga un poquito de verg√ºenza , por √∫ltimo respete que estamos en Semana Santa!\n",
      "En la Cat√≥lica , que le parece.\n",
      "Aaaa y para qu√© decir el sinverguenza del canciller.\n",
      "Mira  este es un ejemplo de como debe funcionar la pol√≠tica exterior. Seguimos üå≥\n",
      "Jajajajajaja\n",
      "Y sigue .... el nuevo Felipe Kast\n",
      "Cuento aparte, llega a su casa y sigue trasmitiendo y haciendo videos, como tan pegado jajajajajaja\n",
      "Jajajajajaja\n",
      "Porque?\n",
      "Que alguien le avise que las AFP  se le adelantaron y ya nos expropiaron/robaron  los fondos .\n",
      "Paso.\n",
      "Ya te pusiste pesado!!!!!!\n",
      "Usted tiene estudios? no parece\n",
      "Entre locos se entienden\n",
      "De cuando ac√°, usted le tiene tanta fe las encuestas.\n",
      "Nadie le aviso a usted que las AFP hace rato que nos expropiaron los fondos .\n",
      "Siempre lo he encontrado raro\n",
      "Bienvenida la cuenta p√∫blica Presidente Boric el 1 de Julio, ser√° hermoso.\n",
      "Porque la Daza anda pase√°ndose todav√≠a ?\n",
      "Grande Atria, lo aplaudo üëèüëèüëèüëèüëèüëèüëèüëèüëèüëèüëèüëè\n",
      "Este qued√≥ herido de gravedad cuando su partido le quit√≥ el piso.\n",
      "De donde saca estas fotos y videos?\n",
      "Rasgando vestiduras\n",
      "Porque coloca dirigido por el convencional? yo no lo veo ah√≠ .\n",
      "Ya las ofreci√≥ , en todo caso sus hijas son adultas.\n",
      "Mire  lo comparan con la Marinovic, ahora entiendo porque le tienen tanta mala .\n",
      "Sin comentarios\n",
      "La Cubilllos dedicada a limpiar el piso de la ‚ÄúMarquesa‚Äù puede haber algo m√°s pat√©tico.\n",
      "Lo incre√≠ble es que no me di cuenta del tiempo, eso es un gran logro.\n",
      "Jajajajajaja que distorsi√≥n de la realidad.\n",
      "Mujer enferma.\n",
      "Ese el problema que tienen no escuchan, entonces despu√©s dicen ‚Äú no lo vi venir‚Äù  \n",
      "Jajajajajajaja üòÇhasta los panelistas se rieron.\n",
      "Su comentario no medita respuesta , el nivel  de la rendici√≥n de la cuenta p√∫blica , habla por si sola.\n",
      "A esto se refer√≠a usted se√±ora \n",
      "Jajajajajaja\n",
      "Fue su hija-adulta- y unas amigas.\n",
      "Y dale!\n",
      "Ajjjjjjj! Que egoc√©ntrico, una lata!\n",
      "Les duele que los ciudadanos sean felices.\n",
      "Sin comentarios ü§¶‚Äç‚ôÄÔ∏è\n",
      "Si uno de estos mejor va mejor con los perfiles del programa.\n",
      "En que andara  ? Despu√©s que pagamos su cuota para el nuevo trabajo que tiene.\n",
      "Excelente!!!! La pura verdad.\n",
      "Jajajajajaja\n",
      "Tendr√≠a que explicarte de nuevo? , mira a tu alrededor y te dar√° cuenta el porqu√©!\n",
      "Que tiene que ver la reineta con su comentario ?\n",
      "Nooo!  para que desgastarse y perder el tiempo con la loca de la Canelo y con usted .\n",
      "Yo tambi√©n\n",
      "Mira  para que no te preocupes. Eso de la ambici√≥n por el poder le pasa a ustedes. Aprendan.\n",
      "Es inevitable , es para la risa quien lo podr√≠a tomar en serio.\n",
      "Cierto\n",
      "Jajajajajaja\n",
      "Jajajajajaja queeeeee\n",
      "üëèüëèüëèüëèüëèüëè\n",
      "Seg√∫n el 22 %\n",
      "A quien le est√° tirando los palos? Diga nombre y apellido . Por √∫ltimo el profesor , sus razones tendr√°. Envidioso.\n",
      "Jajajajajaja\n",
      "Jajajajajaja es pat√©tico\n",
      "Ooooo!!!! Que sorpresa nunca la Derecha a trav√©s de la Historia de Chile a abogado por los desechos de los pueblos ind√≠genas.\n",
      "No todo se trata de usted.\n",
      "Ya te dijeron,es mentira !\n",
      "No fue!!!! No creo que lo echen de menos\n",
      "Entonces aprobamos !\n",
      "La loca de la Tere? Jajajajajaja\n",
      "Porque no?\n",
      "y su √©tica donde est√°? A lo que lleva el fanatismo.\n",
      "Jajajajajaja\n",
      "Jajajajajaja salt√≥ el man√≠.\n",
      "Noooooooooooooooooo!!\n",
      "Usted ha tenido trato directo con Felipe Kast ?puede que se haya contagiado , rev√≠sese por si acaso .\n",
      "Jajajajajaja me gusta su perseverancia! Aunque sea en la mentira camuflada.\n",
      "Esta es la gur√∫ de la \n",
      "Quien dice que es la mayor√≠a de los chilenos? Porque se habla en nombre de los ciudadanos?\n",
      "Y pensar que le pagamos a la parejita de  y  para que se consiguieran esa peguita. Sinverguenzas!!!!\n",
      "Ni el m√°s m√≠nimo escr√∫pulo para mentir, cuanta miseria. Fue invitado por un convencional no es invitado de honor.\n",
      "Seguir√≠a siendo el 20%\n",
      "Eso depende a qu√© le llama usted inteligencia.\n",
      "Iba a pasar de largo pero no pude evitar reine de tanta tontera que habla \n",
      "Como les duele!!!! Vamos bien entonces #AprueboPlebicitoDeSalida\n",
      "Como si hubi√©ramos podido elegir alguna vez!!\n",
      "ü§¶‚Äç‚ôÄÔ∏èMi Dios!!!!  Esto es fanatismo puro.\n",
      "Jajajajajaja hay que ver que ordinaria es la Derecha.\n",
      "Jajajajajaja no creo!!! Y si viene de usted la consideraci√≥n creo que suma puntos.\n",
      "Tenga cuidado no sea que termine como Tomas Jocelyn Holt.\n",
      "Este video no est√° completo ojo!\n",
      "Estaba ocupada defendiendo el franquismo. Del cual su familia form√≥ parte. Son de la misma cala√±a.\n",
      "La Marquesa hablando de plurinacionalidad, de verdad la Derecha nos tiene por estupidos.\n",
      "Tal cual esta es la Derecha que grita libertad de expresi√≥n!!!!\n",
      "Jajajajajaja hay que estar muy carente para creerle a   !!!!\n",
      "Defendiendo a la Marqueza!!!! que  viene a educar a los indios, tenga m√°s dignidad.\n",
      "Estudia Derecho de nuevo!\n",
      "No entend√≠ nada porque hablo ella sola\n",
      "Sin argumento , su respuesta es solo reactiva y visceral, fue muy  buena la cuenta p√∫blica.\n",
      "Locura! La suya\n",
      "Bueno el Photoshop jajajajajaja hasta en las fotos es falsa la \n",
      "Jajajajajaja no hay vuelta atr√°s, si los dinosaurios se extinguieron, imag√≠nese!\n",
      "Jajajajajaja delirantes . Que locura! no tienen l√≠mites para mentir.\n",
      "Yo le creo a personas como Roberto Celedon. Toda mi confianza all√≠ puesta.\n",
      "Jajajajajaja\n",
      "Jajajajajaja\n",
      "ü§¶‚Äç‚ôÄÔ∏è\n",
      "Hay que estar muy desesperada para re twittear a  jajajajajaja\n"
     ]
    }
   ],
   "source": [
    "show_similar_pair(user, list(users.keys())[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos usuarios similares a \"CarlosEsDelAlbo\" utilizando la funci√≥n ya discutida \"get_similar_users\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user, users = get_similar_users(df, tweets_similares, big_tweets, 'CarlosEsDelAlbo')\n",
    "clear_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los usuarios m√°s similares a \"jnfernandez\" junto a su similaridad promedio y la cantidad de tweets similares en total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los usuarios m√°s similares a CarlosEsDelAlbo son\n",
      "1. EsVictorHugo con una similaridad de 0.8877192982456139 para 14 tweets.\n",
      "2. LorenaTzoc con una similaridad de 0.845022624434389 para 26 tweets.\n",
      "3. vrojas007 con una similaridad de 0.80344409027979 para 30 tweets.\n",
      "4. Paomotion con una similaridad de 0.7493578723834563 para 10 tweets.\n",
      "5. AlvaroBots_ con una similaridad de 0.7455341650830372 para 14 tweets.\n",
      "6. soniadederecha con una similaridad de 0.7373641278303646 para 58 tweets.\n",
      "7. LourdesGavar con una similaridad de 0.7333333333333334 para 10 tweets.\n",
      "8. bybleanstartup con una similaridad de 0.7330688777036499 para 41 tweets.\n",
      "9. fgb_sw con una similaridad de 0.730786886807141 para 14 tweets.\n",
      "10. rodvalpablo con una similaridad de 0.726790450928382 para 12 tweets.\n",
      "11. Jo5836613057 con una similaridad de 0.7059702554614672 para 12 tweets.\n",
      "12. AngelDLaCruz_ con una similaridad de 0.6953763671717832 para 18 tweets.\n",
      "13. SuknoR con una similaridad de 0.6931773879142301 para 10 tweets.\n",
      "14. PATEFUE con una similaridad de 0.6844099794594845 para 11 tweets.\n",
      "15. monicanavarrob con una similaridad de 0.6686931741700214 para 34 tweets.\n",
      "16. Adanjulio2012 con una similaridad de 0.6679137439428386 para 32 tweets.\n",
      "17. GaldamesMonica con una similaridad de 0.6663255196606611 para 28 tweets.\n",
      "18. Pame4378 con una similaridad de 0.6587301587301587 para 14 tweets.\n",
      "19. ftaladriz con una similaridad de 0.6560271646859084 para 10 tweets.\n",
      "20. jp_stg_cl con una similaridad de 0.6525947287237609 para 10 tweets.\n",
      "21. cahp71 con una similaridad de 0.6518181818181811 para 76 tweets.\n",
      "22. Chileno_Rockero con una similaridad de 0.6461538461538463 para 10 tweets.\n",
      "23. chileno_solo con una similaridad de 0.642857142857143 para 10 tweets.\n",
      "24. Cris__chile con una similaridad de 0.6346940358348185 para 40 tweets.\n",
      "25. ACR8667 con una similaridad de 0.6344129643062316 para 29 tweets.\n",
      "26. petereta69 con una similaridad de 0.6305522208883554 para 14 tweets.\n",
      "27. monroeyfrida con una similaridad de 0.6265001718409897 para 14 tweets.\n",
      "28. ogym21 con una similaridad de 0.6256886894248729 para 98 tweets.\n",
      "29. CelesteStrau con una similaridad de 0.6205808080808078 para 16 tweets.\n",
      "30. Natu_gs con una similaridad de 0.6199619632132012 para 72 tweets.\n",
      "31. Baldito_28 con una similaridad de 0.6198856457489276 para 27 tweets.\n",
      "32. pantrotigro con una similaridad de 0.615227191677726 para 116 tweets.\n",
      "33. Asantis70 con una similaridad de 0.6118260581247837 para 10 tweets.\n",
      "34. SolZophie con una similaridad de 0.6109231134314191 para 14 tweets.\n",
      "35. AnriquezJara con una similaridad de 0.6107998040299502 para 30 tweets.\n",
      "36. MateolivaOliva con una similaridad de 0.6078042328042326 para 24 tweets.\n",
      "37. Anitace con una similaridad de 0.607446088322954 para 12 tweets.\n",
      "38. Gonzo35974897 con una similaridad de 0.6071255788236921 para 14 tweets.\n",
      "39. fcojcornejo con una similaridad de 0.6042120756074244 para 18 tweets.\n",
      "40. AndrewROpinante con una similaridad de 0.6042016677318706 para 14 tweets.\n",
      "41. tichecha con una similaridad de 0.6038580772488712 para 14 tweets.\n",
      "42. chinoani con una similaridad de 0.6008104298801973 para 14 tweets.\n",
      "43. JORGE_KATANA con una similaridad de 0.598772775218329 para 30 tweets.\n",
      "44. the_hnp con una similaridad de 0.5938086326557506 para 21 tweets.\n",
      "45. moalur con una similaridad de 0.5921127105502376 para 43 tweets.\n",
      "46. LobosDrago con una similaridad de 0.5900383141762453 para 12 tweets.\n",
      "47. Rosario77488957 con una similaridad de 0.5890912651782217 para 12 tweets.\n",
      "48. Chuncho54 con una similaridad de 0.5880919791521882 para 68 tweets.\n",
      "49. FranciscoCuent4 con una similaridad de 0.5861781076066789 para 44 tweets.\n",
      "50. mptellechea con una similaridad de 0.5857821318857603 para 22 tweets.\n",
      "51. PiolaBajoPerfi1 con una similaridad de 0.5842760293979805 para 20 tweets.\n",
      "52. RalMuozE con una similaridad de 0.5835727088886846 para 10 tweets.\n",
      "53. AFZamorano con una similaridad de 0.5800956087871693 para 13 tweets.\n",
      "54. serenitynow45 con una similaridad de 0.5800000000000001 para 10 tweets.\n",
      "55. magdale86085395 con una similaridad de 0.5769637259137862 para 38 tweets.\n",
      "56. patty_alvi con una similaridad de 0.5742941970310392 para 10 tweets.\n",
      "57. jiba1971 con una similaridad de 0.574034062595747 para 18 tweets.\n",
      "58. efesios2dos con una similaridad de 0.5728758627434922 para 23 tweets.\n",
      "59. vikina con una similaridad de 0.5725203658502424 para 68 tweets.\n",
      "60. ange_sepulvedam con una similaridad de 0.5696905930948483 para 10 tweets.\n",
      "61. DGBA53 con una similaridad de 0.5676980847435393 para 22 tweets.\n",
      "62. maroespartano con una similaridad de 0.5673826862792379 para 10 tweets.\n",
      "63. porunavidalibre con una similaridad de 0.5652696217534565 para 22 tweets.\n",
      "64. RiofrioMariela con una similaridad de 0.5624586449615122 para 14 tweets.\n",
      "65. clauriv56002711 con una similaridad de 0.5593408784102804 para 58 tweets.\n",
      "66. FonolaHGV con una similaridad de 0.5576976549169479 para 60 tweets.\n",
      "67. filatelia1967 con una similaridad de 0.5556469500381216 para 30 tweets.\n",
      "68. Csrmen22887832 con una similaridad de 0.5553929249555746 para 38 tweets.\n",
      "69. eduardolirat con una similaridad de 0.5553547929291521 para 32 tweets.\n",
      "70. Del44xCiento con una similaridad de 0.5553274150333958 para 15 tweets.\n",
      "71. Alejand41647081 con una similaridad de 0.5545138049323106 para 340 tweets.\n",
      "72. VFrancisca_Ch con una similaridad de 0.5496333281323138 para 10 tweets.\n",
      "73. pembry1969 con una similaridad de 0.5490397038362154 para 24 tweets.\n",
      "74. Fernand99831598 con una similaridad de 0.5483869931238352 para 10 tweets.\n",
      "75. LuisMM030407 con una similaridad de 0.5472078870496592 para 20 tweets.\n",
      "76. vivaChile22 con una similaridad de 0.5465979917701878 para 32 tweets.\n",
      "77. canaito031 con una similaridad de 0.5441559187392729 para 234 tweets.\n",
      "78. nancyrodrigg con una similaridad de 0.5436471475925608 para 50 tweets.\n",
      "79. Marce5016 con una similaridad de 0.5394871794871794 para 10 tweets.\n",
      "80. carmenle169 con una similaridad de 0.5391788716454422 para 31 tweets.\n",
      "81. Cristia27505365 con una similaridad de 0.539129427732959 para 12 tweets.\n",
      "82. DanyG94946959 con una similaridad de 0.5386819670811417 para 14 tweets.\n",
      "83. DorisDi050664 con una similaridad de 0.5381027302653236 para 28 tweets.\n",
      "84. 007Artemisa con una similaridad de 0.5374661463331415 para 11 tweets.\n",
      "85. eccpatriota con una similaridad de 0.5345452485291912 para 12 tweets.\n",
      "86. Sam49976234 con una similaridad de 0.5340012072951632 para 20 tweets.\n",
      "87. fj_cancino con una similaridad de 0.5326951584509907 para 58 tweets.\n",
      "88. GuzmanLlabur con una similaridad de 0.5319029865361492 para 30 tweets.\n",
      "89. Caro89828340 con una similaridad de 0.5302096188284177 para 23 tweets.\n",
      "90. Rodry_alonso con una similaridad de 0.5294399181469559 para 13 tweets.\n",
      "91. pabloognob con una similaridad de 0.5237572074177964 para 20 tweets.\n",
      "92. AndreaLaCoss con una similaridad de 0.5215482121485628 para 14 tweets.\n",
      "93. Jose57278232 con una similaridad de 0.5212644368597878 para 16 tweets.\n",
      "94. mairicio con una similaridad de 0.5200306971579587 para 22 tweets.\n",
      "95. bconaaa con una similaridad de 0.520002279329994 para 25 tweets.\n",
      "96. Gusrichtig con una similaridad de 0.5197407666369764 para 50 tweets.\n",
      "97. michelan195 con una similaridad de 0.5191686199078591 para 64 tweets.\n",
      "98. Jaime96413333 con una similaridad de 0.5174357081333825 para 18 tweets.\n",
      "99. MarCe_0018 con una similaridad de 0.516689550134443 para 14 tweets.\n",
      "100. karinsoti con una similaridad de 0.5159868236613401 para 12 tweets.\n",
      "101. AtreidesDemian con una similaridad de 0.5132138585070992 para 26 tweets.\n",
      "102. Amy03898327 con una similaridad de 0.5120510648552096 para 137 tweets.\n",
      "103. csepulvedatoro con una similaridad de 0.5120333265359056 para 20 tweets.\n",
      "104. oscarro79128904 con una similaridad de 0.5108883850286476 para 111 tweets.\n",
      "105. TigreRockero2 con una similaridad de 0.5091937025930102 para 54 tweets.\n",
      "106. alexvotakast con una similaridad de 0.5076810268363108 para 16 tweets.\n",
      "107. Isitacake con una similaridad de 0.5075072463768115 para 10 tweets.\n",
      "108. YDchileM con una similaridad de 0.5073565149623718 para 52 tweets.\n",
      "109. ccgrum con una similaridad de 0.5072242913502918 para 16 tweets.\n",
      "110. samukeitor98 con una similaridad de 0.5061163138793255 para 36 tweets.\n",
      "111. ayala_rodolfo con una similaridad de 0.5054780905081304 para 60 tweets.\n",
      "112. NathalyLarsen con una similaridad de 0.5050778803773359 para 20 tweets.\n",
      "113. fn19100 con una similaridad de 0.5048423062131349 para 32 tweets.\n",
      "114. hrng777 con una similaridad de 0.5041221486877129 para 14 tweets.\n",
      "115. Simplem77833982 con una similaridad de 0.5039191529031135 para 14 tweets.\n",
      "116. libertariochi con una similaridad de 0.5037657361795295 para 12 tweets.\n",
      "117. edgardohapke con una similaridad de 0.5020646428235168 para 22 tweets.\n",
      "118. RUBEN_ANTIYAL con una similaridad de 0.5020518328789005 para 20 tweets.\n",
      "119. Deberpatriota con una similaridad de 0.5008266850496953 para 12 tweets.\n",
      "120. IsabelV36842300 con una similaridad de 0.5001586518419888 para 40 tweets.\n"
     ]
    }
   ],
   "source": [
    "print_similar_users(user, users)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos el perfil del usuario con el que partimos y su usuario m√°s \"similar\". Se puede ver que ambos tienen contenido similar del Rechazo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfil del Usuario CarlosEsDelAlbo\n",
      "El vuelo nunca fuea brea culiao\n",
      "Lo de la libertad pas√≥ piola, se mand√≥ dos cagazos en una frase de 1 minuto\n",
      "Pero si Lagos ya lo dijo, si gana rechazo sigue la constituci√≥n que hizo √©l\n",
      "Puras felicitaciones, como dec√≠a Ma√±alich hajajaj\n",
      "Ten√≠a que salir una defensora de los narcos del sur\n",
      "Y lo malo es que no le pasar√° nada, Adrian tiene mucha influencia desde el gobierno de Bachelet\n",
      "Se debe ir a la chucha, m√≠nimo, pero primero acusaci√≥n constitucional\n",
      "Se qued√≥ callado el zurdo\n",
      "El que lo necesita es porque no se sac√≥ debidamente la chucha trabajando\n",
      "Con los impuestos se financia a cada vago del congreso y la moneda, tampoco deber√≠amos pagarlos\n",
      "Aunque te duela el hoyo vieja culia \n",
      "Tiene raz√≥n y eso que voy por el Rechazo, si se aprueba el Mamarracho deben haber elecciones nuevas\n",
      "Si como se regula hasta ahora por el norte\n",
      "Dile a los borrachos pasteros de la convenci√≥n que dejen de hacerse autogoles, #ElRechazoCrece\n",
      "Es el pelao culiao de las series\n",
      "Le dan hasta √≥rdenes al mechero con TOC \n",
      "Te pillaron pelao \n",
      "Por si no sabes lo dona, costal de weas\n",
      "No somos M√©xico y ojal√° nunca lleguemos a serlo\n",
      "La wea que menos importa es esa\n",
      "Y lo malo es que no le pasar√° nada, Atria tiene mucha influencia desde el gobierno de Bachelet\n",
      "Pluriphone 13 #iPhone13  \n",
      "Anda a jugar PES vo nomas\n",
      "Portadas que no envejecen\n",
      "Ya lleg√≥ un familiar del pelao  ?\n",
      "#RechazoElMamarracho\n",
      "Jueron loh pakoh\n",
      "#RechazoElMamarracho\n",
      "No es gobierno te est√°n diciendo matewea\n",
      "Que ser√≠a periodismo de calidad? Que no se les critique a estos mateweas?\n",
      "Deja imprimirlo pa ir a limpiarme el poto\n",
      "Incluso m√°s que Kast que se nos est√° poniendo amarillo\n",
      "Te queda poco vieja del orto, aprovecha estos meses de fama\n",
      "Jajajaja mechero culiao\n",
      "¬øQuieren cajitas feliz los weones?\n",
      "D√≠ganle a esta vieja culia que se hacen mala propaganda solos los chuchesumares de la Convenci√≥n\n",
      "No debe pensar si vot√≥ por Boric\n",
      "Que vayan a votar el 4 de septiembre rechazo y se acaba la wea\n",
      "Se viene el rechazo zurdos infelices\n",
      "Como lo dice la bandera de la portada,   partieron a Chile en pedacitos\n",
      "Yo quiero isapre, ni cagando me atenderla en un cesfam\n",
      "El weon de arriba compra guaguas\n",
      "Los vagos culiaos de la confusam estar√≠an en su salsa\n",
      "Porque quieren eliminar las isapres matewea, quieren que todos estemos en esa caga de fonasa\n",
      "Cag√≥ el mechero\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Perfil del Usuario EsVictorHugo\n",
      "#RechazoElMamarracho\n",
      "#Taradit se supera a s√≠ mismo.\n",
      "Es un asco. #RechazoElMamarracho\n",
      "Que personalidad para mostrar su pobreza cognitiva!\n",
      "#RechazoElMamarracho\n",
      "#RecuentoParaleloAServel\n",
      "Otra que no entiende lo que lee.\n",
      "La Ministra del interior se saca selfis cosechando naranjas en su predio.\n",
      "¬øD√≥nde se puede ver el discurso que hizo Roc√≠o Cantuarias? Hoy lo mostraron en Emol. \n",
      "#RechazoElMamarracho\n",
      "Taradit en su mejor alucinaci√≥n.\n",
      "Lo dicho por Taradit es Falso.\n",
      "#RechazoElMamarracho.\n",
      "#RechazoElMamarracho\n",
      "#RechazoElMamarracho \n",
      "#RechazoCrece\n",
      "Antes los consider√°bamos pelotudos, pero hora  se ganaron la denominaci√≥n: Pluripelotudos\n"
     ]
    }
   ],
   "source": [
    "show_similar_pair(user, list(users.keys())[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos usuarios similares a un usuario generado al azar utilizando la funci√≥n ya discutida \"get_similar_users\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user, users = get_similar_users(df, tweets_similares, big_tweets)\n",
    "clear_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los usuarios m√°s similares a este usuario al azar junto a su similaridad promedio y la cantidad de tweets similares en total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los usuarios m√°s similares a rodrigoorellana son\n",
      "1. jpkramer63 con una similaridad de 0.9333333333333332 para 25 tweets.\n",
      "2. vbmchile con una similaridad de 0.9242424242424242 para 10 tweets.\n",
      "3. ArturoRuizTagle con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "4. Joselfo4 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "5. mnlacolina con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "6. Fernand02146611 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "7. jaime51977006 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "8. pboettcher_10 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "9. manhumeres con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "10. mackvision2 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "11. josemartinezcur con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "12. juangronne con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "13. RICHISANDONAI con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "14. sandrotronix con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "15. Edu46615317 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "16. Apruevonao con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "17. ferno33 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "18. Cristia74551365 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "19. avega21699851 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "20. Rvargas82517252 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "21. Reyko662 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "22. Carlos68841360 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "23. 3Xemito con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "24. gonzalosabe con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "25. jemito68 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "26. nosfuismosalab con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "27. MoyaGaldame con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "28. Diego54230639 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "29. VictorF23981941 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "30. MadariagaNeira con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "31. SdorenV con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "32. lina_truan con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "33. camane677 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "34. JorgePa36538246 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "35. agonzalezzamora con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "36. duckvaldiviano con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "37. edison3863 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "38. Mirna32120790 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "39. mecampos_cl con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "40. Miguel_Gavilan2 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "41. Andre_Lye2 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "42. Luis16748020 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "43. Fender_Madrid con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "44. gerardoamb1979 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "45. MelyTere2 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "46. guille32 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "47. FeliuKinast con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "48. damaryssadradin con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "49. ojosoez con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "50. EKtkry con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "51. rikirev con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "52. EnriquetaMarzan con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "53. araniz6 con una similaridad de 0.7752136752136755 para 12 tweets.\n",
      "54. nabohead con una similaridad de 0.7752136752136753 para 18 tweets.\n",
      "55. cazaux_andres con una similaridad de 0.7752136752136753 para 18 tweets.\n",
      "56. cfespina con una similaridad de 0.7752136752136753 para 18 tweets.\n",
      "57. Outside92509562 con una similaridad de 0.7752136752136753 para 18 tweets.\n",
      "58. josenavilla con una similaridad de 0.7752136752136753 para 18 tweets.\n",
      "59. edorobi73 con una similaridad de 0.7752136752136753 para 18 tweets.\n",
      "60. alfredodelano con una similaridad de 0.7752136752136753 para 18 tweets.\n",
      "61. garymej con una similaridad de 0.7752136752136753 para 18 tweets.\n",
      "62. Grifo35 con una similaridad de 0.7752136752136753 para 18 tweets.\n",
      "63. jarar_azul con una similaridad de 0.7752136752136753 para 18 tweets.\n",
      "64. papsdixi con una similaridad de 0.7752136752136753 para 18 tweets.\n",
      "65. Fco__Vasquez con una similaridad de 0.7752136752136753 para 18 tweets.\n",
      "66. elyhn1 con una similaridad de 0.7752136752136753 para 18 tweets.\n",
      "67. boberck con una similaridad de 0.7752136752136752 para 30 tweets.\n",
      "68. PabloAndriu con una similaridad de 0.7752136752136751 para 36 tweets.\n",
      "69. Alejand32306857 con una similaridad de 0.7752136752136751 para 24 tweets.\n",
      "70. nelsonfb2016 con una similaridad de 0.7752136752136751 para 24 tweets.\n",
      "71. demanjar69 con una similaridad de 0.7752136752136751 para 24 tweets.\n",
      "72. liliana74963389 con una similaridad de 0.7676384498302306 para 73 tweets.\n",
      "73. Alex_EXQUELETOR con una similaridad de 0.7554655870445346 para 19 tweets.\n",
      "74. GoldeFrancoD con una similaridad de 0.7540704193765417 para 49 tweets.\n",
      "75. paulamartinezm1 con una similaridad de 0.7479010307735168 para 86 tweets.\n",
      "76. ANTONEL36607816 con una similaridad de 0.7472809141926813 para 296 tweets.\n",
      "77. mamagritona3 con una similaridad de 0.7455967643467644 para 24 tweets.\n",
      "78. CristinaSwider1 con una similaridad de 0.7453778677462889 para 19 tweets.\n",
      "79. RivanoSalas con una similaridad de 0.7422090729783039 para 13 tweets.\n",
      "80. jacquel87252596 con una similaridad de 0.7403071287686674 para 13 tweets.\n",
      "81. IquiqueViva con una similaridad de 0.7400384815680391 para 55 tweets.\n",
      "82. Caramori85 con una similaridad de 0.7371571410615527 para 80 tweets.\n",
      "83. AndresL33620976 con una similaridad de 0.7367241554741555 para 42 tweets.\n",
      "84. Aves82241081 con una similaridad de 0.7357244607244608 para 18 tweets.\n",
      "85. Gicp701 con una similaridad de 0.7357244607244608 para 18 tweets.\n",
      "86. mariojorrquera con una similaridad de 0.7357244607244608 para 18 tweets.\n",
      "87. Solism1M con una similaridad de 0.734812623274162 para 13 tweets.\n",
      "88. AeccCayv77 con una similaridad de 0.7319484661546856 para 13 tweets.\n",
      "89. BorisTadres con una similaridad de 0.7315470209519558 para 13 tweets.\n",
      "90. Berti29272678 con una similaridad de 0.7298551580344135 para 119 tweets.\n",
      "91. Diegol6662 con una similaridad de 0.7296639645338738 para 78 tweets.\n",
      "92. Tatita6969 con una similaridad de 0.7290893015030945 para 29 tweets.\n",
      "93. MariapazNez1 con una similaridad de 0.7255591168091168 para 60 tweets.\n",
      "94. gaete_yan con una similaridad de 0.7241506859153916 para 24 tweets.\n",
      "95. ChiskoFuentes con una similaridad de 0.720436931895265 para 72 tweets.\n",
      "96. paredestwit con una similaridad de 0.7189213312652071 para 73 tweets.\n",
      "97. CompaeroMillon1 con una similaridad de 0.7184979742774014 para 41 tweets.\n",
      "98. fcoraw con una similaridad de 0.7159798534798535 para 12 tweets.\n",
      "99. Rocierateamo con una similaridad de 0.7159798534798535 para 12 tweets.\n",
      "100. AgathaCristhie7 con una similaridad de 0.7159798534798535 para 12 tweets.\n",
      "101. 63dus con una similaridad de 0.7159798534798535 para 12 tweets.\n",
      "102. JulioDo89187637 con una similaridad de 0.7159798534798535 para 12 tweets.\n",
      "103. Abner_Gutierrez con una similaridad de 0.7159798534798535 para 12 tweets.\n",
      "104. Cancerbero822 con una similaridad de 0.7159798534798535 para 12 tweets.\n",
      "105. ignacio32azul con una similaridad de 0.7159798534798535 para 12 tweets.\n",
      "106. M1917Henriquez con una similaridad de 0.7159798534798535 para 12 tweets.\n",
      "107. Francis65415726 con una similaridad de 0.7159798534798535 para 12 tweets.\n",
      "108. Jandr0_L con una similaridad de 0.7159798534798535 para 12 tweets.\n",
      "109. aeotorres con una similaridad de 0.7159798534798535 para 12 tweets.\n",
      "110. Antonio95833855 con una similaridad de 0.7159798534798535 para 12 tweets.\n",
      "111. lfsilvac con una similaridad de 0.7135073260073258 para 24 tweets.\n",
      "112. griselda_gigi con una similaridad de 0.7071296894826307 para 18 tweets.\n",
      "113. tindala25 con una similaridad de 0.7071296894826307 para 18 tweets.\n",
      "114. marire52 con una similaridad de 0.7064856711915535 para 28 tweets.\n",
      "115. Valenzuela_Lav con una similaridad de 0.7041514041514042 para 14 tweets.\n",
      "116. ValerieMoir con una similaridad de 0.7037440857753358 para 48 tweets.\n",
      "117. Leomoraleslara con una similaridad de 0.7035179918121092 para 25 tweets.\n",
      "118. minerossierra con una similaridad de 0.7006715506715507 para 18 tweets.\n",
      "119. LuciaLabra2 con una similaridad de 0.6958214624881293 para 18 tweets.\n",
      "120. brevis_rosa con una similaridad de 0.6949888880923363 para 29 tweets.\n",
      "121. lavidaesahora_ con una similaridad de 0.6948717948717952 para 22 tweets.\n",
      "122. patrici52051548 con una similaridad de 0.6928827084433492 para 23 tweets.\n",
      "123. RiquelmeAlister con una similaridad de 0.6912420912420912 para 11 tweets.\n",
      "124. COKEPATRICIO con una similaridad de 0.6912420912420912 para 11 tweets.\n",
      "125. _MEMPHIS_ con una similaridad de 0.690343070215603 para 32 tweets.\n",
      "126. kokevelozo con una similaridad de 0.6892445611069095 para 13 tweets.\n",
      "127. VidalIlich con una similaridad de 0.6877140205436285 para 82 tweets.\n",
      "128. Cristobal84Bc con una similaridad de 0.685617957590276 para 17 tweets.\n",
      "129. djnsa con una similaridad de 0.6854047958214625 para 18 tweets.\n",
      "130. CristianCrden11 con una similaridad de 0.6816368866484965 para 48 tweets.\n",
      "131. ValenzuelaSussy con una similaridad de 0.6811965811965813 para 17 tweets.\n",
      "132. BulboaMario con una similaridad de 0.6804395604395607 para 60 tweets.\n",
      "133. HaydeeBazaes con una similaridad de 0.6786821873778397 para 23 tweets.\n",
      "134. Eduardo42111919 con una similaridad de 0.6775641025641027 para 16 tweets.\n",
      "135. betty_galdames con una similaridad de 0.6775641025641027 para 16 tweets.\n",
      "136. firulayvillano con una similaridad de 0.6766835728374191 para 13 tweets.\n",
      "137. Angelin90790483 con una similaridad de 0.6738436400201107 para 17 tweets.\n",
      "138. elzapatovieja con una similaridad de 0.6736223571749888 para 19 tweets.\n",
      "139. GatoAnticomunis con una similaridad de 0.6731597092278205 para 34 tweets.\n",
      "140. Pato_ZAP con una similaridad de 0.6730876966171085 para 12 tweets.\n",
      "141. Alejo30050816 con una similaridad de 0.6730876966171085 para 12 tweets.\n",
      "142. SoleBerr con una similaridad de 0.6730876966171085 para 12 tweets.\n",
      "143. YanezYocely con una similaridad de 0.6730876966171085 para 12 tweets.\n",
      "144. ADenevi con una similaridad de 0.6730876966171085 para 12 tweets.\n",
      "145. nelzonespace con una similaridad de 0.6730876966171085 para 12 tweets.\n",
      "146. teresatassara con una similaridad de 0.6730876966171085 para 12 tweets.\n",
      "147. Claudia44027104 con una similaridad de 0.6730876966171083 para 24 tweets.\n",
      "148. Tanalana65 con una similaridad de 0.6730876966171083 para 12 tweets.\n",
      "149. Nicolassymmes con una similaridad de 0.6730876966171083 para 12 tweets.\n",
      "150. Enocjz5 con una similaridad de 0.6730876966171083 para 12 tweets.\n",
      "151. Matiasvleal con una similaridad de 0.6730876966171083 para 12 tweets.\n",
      "152. kihugo25m con una similaridad de 0.6730876966171083 para 12 tweets.\n",
      "153. Rcuadra6 con una similaridad de 0.6730876966171083 para 36 tweets.\n",
      "154. Pavel94687468 con una similaridad de 0.6730876966171083 para 12 tweets.\n",
      "155. UmanlagTrini con una similaridad de 0.6730876966171083 para 12 tweets.\n",
      "156. MrUnder17 con una similaridad de 0.6730876966171083 para 12 tweets.\n",
      "157. butter_fly_75 con una similaridad de 0.6730876966171083 para 12 tweets.\n",
      "158. cbarriaz con una similaridad de 0.6712161172161174 para 25 tweets.\n",
      "159. Liberal20202 con una similaridad de 0.6703568361463101 para 19 tweets.\n",
      "160. Matias55556704 con una similaridad de 0.6683196355465262 para 28 tweets.\n",
      "161. soyelfele con una similaridad de 0.6676404749934162 para 18 tweets.\n",
      "162. rubenhe41255353 con una similaridad de 0.6676404749934162 para 18 tweets.\n",
      "163. Pilar79720762 con una similaridad de 0.667412458271184 para 38 tweets.\n",
      "164. AlvaroAnti con una similaridad de 0.6654329245633595 para 23 tweets.\n",
      "165. Slabarca con una similaridad de 0.6647435897435898 para 16 tweets.\n",
      "166. JavierM94597691 con una similaridad de 0.6634004884004884 para 12 tweets.\n",
      "167. dicosmo_rodrigo con una similaridad de 0.6634004884004884 para 12 tweets.\n",
      "168. rmeinas con una similaridad de 0.6625624375624378 para 22 tweets.\n",
      "169. solano_jota con una similaridad de 0.6604018756478709 para 46 tweets.\n",
      "170. LofMapu con una similaridad de 0.6599547511312218 para 17 tweets.\n",
      "171. Guido74713197 con una similaridad de 0.6599547511312217 para 17 tweets.\n",
      "172. JeannetteGuzm11 con una similaridad de 0.6594883961188391 para 119 tweets.\n",
      "173. OLIVIA_XG con una similaridad de 0.6582945728898846 para 28 tweets.\n",
      "174. Carlota01584099 con una similaridad de 0.6574136008918617 para 23 tweets.\n",
      "175. JorgeMassardo2 con una similaridad de 0.6567460317460317 para 24 tweets.\n",
      "176. Mytochile con una similaridad de 0.6567460317460317 para 18 tweets.\n",
      "177. NatitoOdiosa con una similaridad de 0.6567460317460317 para 18 tweets.\n",
      "178. karitodelc con una similaridad de 0.6567460317460317 para 18 tweets.\n",
      "179. ourson1 con una similaridad de 0.6567460317460317 para 18 tweets.\n",
      "180. Sean_Seios con una similaridad de 0.6567460317460317 para 18 tweets.\n",
      "181. rexvidal con una similaridad de 0.6567460317460316 para 12 tweets.\n",
      "182. denuevo2013 con una similaridad de 0.6567460317460316 para 12 tweets.\n",
      "183. ppintoa con una similaridad de 0.6567460317460316 para 12 tweets.\n",
      "184. hildengarden con una similaridad de 0.6567460317460316 para 12 tweets.\n",
      "185. perritamd con una similaridad de 0.6567460317460316 para 12 tweets.\n",
      "186. JosMigu77360272 con una similaridad de 0.6567460317460316 para 12 tweets.\n",
      "187. R26DURAN con una similaridad de 0.6567460317460316 para 12 tweets.\n",
      "188. SerapioSabino con una similaridad de 0.6567460317460316 para 12 tweets.\n",
      "189. chipamoclit con una similaridad de 0.6567460317460316 para 12 tweets.\n",
      "190. RepublicanoChi con una similaridad de 0.6567460317460316 para 12 tweets.\n",
      "191. OscarLosLagos con una similaridad de 0.6567460317460316 para 12 tweets.\n",
      "192. Epr_____ con una similaridad de 0.6567460317460316 para 12 tweets.\n",
      "193. evelininini con una similaridad de 0.6567460317460316 para 12 tweets.\n",
      "194. Andrs46157988 con una similaridad de 0.6561253561253563 para 12 tweets.\n",
      "195. borishmelochupa con una similaridad de 0.6557710888145671 para 23 tweets.\n",
      "196. francis01014804 con una similaridad de 0.6551437805891586 para 25 tweets.\n",
      "197. grojas7171 con una similaridad de 0.6536996336996336 para 30 tweets.\n",
      "198. aliciaparcelera con una similaridad de 0.6529867247919986 para 87 tweets.\n",
      "199. ccastroh1 con una similaridad de 0.6526820021653614 para 80 tweets.\n",
      "200. EugeniaGarreton con una similaridad de 0.6517129928894636 para 17 tweets.\n",
      "201. JpJpmh13294288 con una similaridad de 0.65067016944845 para 39 tweets.\n",
      "202. javierc38692119 con una similaridad de 0.6498982498982497 para 36 tweets.\n",
      "203. arc246566 con una similaridad de 0.6498032669085302 para 22 tweets.\n",
      "204. Opinante12 con una similaridad de 0.64934851473313 para 39 tweets.\n",
      "205. monaherna con una similaridad de 0.6469527455952796 para 13 tweets.\n",
      "206. claugonzu con una similaridad de 0.6469463869463868 para 10 tweets.\n",
      "207. NatSaGri con una similaridad de 0.6455549932523617 para 32 tweets.\n",
      "208. rodramirez10 con una similaridad de 0.6446122504946036 para 17 tweets.\n",
      "209. Divasto con una similaridad de 0.6446122504946036 para 17 tweets.\n",
      "210. ElAntineutrino con una similaridad de 0.6442168770342146 para 17 tweets.\n",
      "211. EduardoCorn con una similaridad de 0.6439102564102566 para 16 tweets.\n",
      "212. JuanLavin7 con una similaridad de 0.6439102564102566 para 16 tweets.\n",
      "213. 123felipoin con una similaridad de 0.6434707857501973 para 24 tweets.\n",
      "214. ciborg3d con una similaridad de 0.6405003561253562 para 12 tweets.\n",
      "215. RocioCaroPinto1 con una similaridad de 0.6405003561253562 para 12 tweets.\n",
      "216. Pepito1956 con una similaridad de 0.6405003561253562 para 12 tweets.\n",
      "217. ric1800 con una similaridad de 0.6396575592271896 para 19 tweets.\n",
      "218. ladyvichile con una similaridad de 0.639384471737413 para 17 tweets.\n",
      "219. camilocc1990 con una similaridad de 0.6388714614778445 para 24 tweets.\n",
      "220. claudioAndre343 con una similaridad de 0.6387788736898309 para 64 tweets.\n",
      "221. VivaChileLibr3 con una similaridad de 0.6384293710001762 para 243 tweets.\n",
      "222. xfarias58 con una similaridad de 0.6382284382284382 para 16 tweets.\n",
      "223. rodrialvaradof con una similaridad de 0.6380158901684762 para 77 tweets.\n",
      "224. Margari93953515 con una similaridad de 0.6370651939705649 para 26 tweets.\n",
      "225. eduardo53382631 con una similaridad de 0.6367746987312206 para 23 tweets.\n",
      "226. EscalaTono con una similaridad de 0.6363508870178166 para 78 tweets.\n",
      "227. rodrigoorellana con una similaridad de 0.6361645201183069 para 38 tweets.\n",
      "228. Nenalopez1Nena con una similaridad de 0.6360843333989115 para 17 tweets.\n",
      "229. JosAnto67759035 con una similaridad de 0.6341612350068231 para 30 tweets.\n",
      "230. JaimeLRojas1 con una similaridad de 0.6322561760917916 para 146 tweets.\n",
      "231. frangallegose con una similaridad de 0.6318828316610926 para 25 tweets.\n",
      "232. jaimeretmen con una similaridad de 0.6317948717948718 para 10 tweets.\n",
      "233. Hvamoschile con una similaridad de 0.6317715508924157 para 89 tweets.\n",
      "234. MarioPu22321263 con una similaridad de 0.6314835066756541 para 43 tweets.\n",
      "235. Edmund_Burke255 con una similaridad de 0.6314493186313357 para 180 tweets.\n",
      "236. antizurdos2121 con una similaridad de 0.6308640163217782 para 35 tweets.\n",
      "237. ManuelD92995640 con una similaridad de 0.6306545209176788 para 20 tweets.\n",
      "238. fchandial con una similaridad de 0.6305700106938497 para 37 tweets.\n",
      "239. renecardenasv con una similaridad de 0.6303314409515406 para 61 tweets.\n",
      "240. dinko_astudillo con una similaridad de 0.6299145299145299 para 11 tweets.\n",
      "241. carcassbodoque con una similaridad de 0.6299145299145299 para 11 tweets.\n",
      "242. juanordenes53 con una similaridad de 0.6299145299145299 para 11 tweets.\n",
      "243. soledad_vallejo con una similaridad de 0.6290363482671175 para 13 tweets.\n",
      "244. milcoantonio con una similaridad de 0.6289689722042661 para 30 tweets.\n",
      "245. bobchile con una similaridad de 0.6281512605042017 para 18 tweets.\n",
      "246. goval1957 con una similaridad de 0.6280830280830281 para 12 tweets.\n",
      "247. naranjaymolesta con una similaridad de 0.6261862844757579 para 40 tweets.\n",
      "248. espunjus1 con una similaridad de 0.6261294261294261 para 18 tweets.\n",
      "249. Polloexpress4 con una similaridad de 0.6259975318798849 para 17 tweets.\n",
      "250. fsepulvedag con una similaridad de 0.6255662341223838 para 11 tweets.\n",
      "251. RichyOrellana con una similaridad de 0.6251452860005494 para 24 tweets.\n",
      "252. Rodrigo86803781 con una similaridad de 0.6251080438378827 para 20 tweets.\n",
      "253. Macavm76 con una similaridad de 0.6244462302131745 para 29 tweets.\n",
      "254. warawarawe con una similaridad de 0.6231104749592143 para 35 tweets.\n",
      "255. ElenaDe42671171 con una similaridad de 0.6230540293040292 para 13 tweets.\n",
      "256. Oscarmartinezam con una similaridad de 0.6230540293040292 para 13 tweets.\n",
      "257. ltolgall con una similaridad de 0.622438616026978 para 32 tweets.\n",
      "258. NelsonRomanqu con una similaridad de 0.6220247073188246 para 24 tweets.\n",
      "259. yplaza con una similaridad de 0.6220061008424183 para 69 tweets.\n",
      "260. JuanCar18109299 con una similaridad de 0.6213784510459703 para 17 tweets.\n",
      "261. NicoRevenge96 con una similaridad de 0.6201174386001842 para 152 tweets.\n",
      "262. MiguelQR3 con una similaridad de 0.619992534698417 para 34 tweets.\n",
      "263. SirPatrickRed con una similaridad de 0.6196104677047288 para 255 tweets.\n",
      "264. DANNYORTE con una similaridad de 0.6195425016062318 para 65 tweets.\n",
      "265. lorenzuela con una similaridad de 0.6190062830687831 para 24 tweets.\n",
      "266. ninocruxado35 con una similaridad de 0.618974358974359 para 10 tweets.\n",
      "267. Rosemar88691813 con una similaridad de 0.618974358974359 para 10 tweets.\n",
      "268. AlfonsoMCarrie con una similaridad de 0.6187234893957582 para 35 tweets.\n",
      "269. SergioLAB1968 con una similaridad de 0.6185508935508935 para 11 tweets.\n",
      "270. pedro_reuque con una similaridad de 0.6185508935508935 para 11 tweets.\n",
      "271. bsantacruzo con una similaridad de 0.6185508935508935 para 11 tweets.\n",
      "272. AlexisSaavedr64 con una similaridad de 0.6184361093452001 para 11 tweets.\n",
      "273. mcbainsalas con una similaridad de 0.617359706959707 para 25 tweets.\n",
      "274. margari19887387 con una similaridad de 0.6173208100904178 para 18 tweets.\n",
      "275. pasosabelle con una similaridad de 0.6172788572442551 para 17 tweets.\n",
      "276. MauricioMuozGue con una similaridad de 0.616429249762583 para 18 tweets.\n",
      "277. chikicriticona con una similaridad de 0.6162518738132463 para 32 tweets.\n",
      "278. jaimeandresm con una similaridad de 0.6154526005516524 para 105 tweets.\n",
      "279. ApolonioToledo con una similaridad de 0.6153247476125099 para 57 tweets.\n",
      "280. AliciaA80121904 con una similaridad de 0.6151098901098901 para 16 tweets.\n",
      "281. wwallace1971 con una similaridad de 0.6151015651015653 para 22 tweets.\n",
      "282. wwgestionglobal con una similaridad de 0.6151015651015652 para 22 tweets.\n",
      "283. NelsonopOrtiz con una similaridad de 0.6148456863627142 para 12 tweets.\n",
      "284. stjimene con una similaridad de 0.6148456863627142 para 12 tweets.\n",
      "285. el_patagon62 con una similaridad de 0.6148456863627142 para 12 tweets.\n",
      "286. magaly_aliantec con una similaridad de 0.6148456863627142 para 12 tweets.\n",
      "287. rrmrz01 con una similaridad de 0.6138538748832868 para 12 tweets.\n",
      "288. Fran3855 con una similaridad de 0.6138538748832867 para 12 tweets.\n",
      "289. AcrolyuLorca con una similaridad de 0.6138538748832867 para 12 tweets.\n",
      "290. ElizabethMD9393 con una similaridad de 0.6138538748832867 para 12 tweets.\n",
      "291. Homero2022 con una similaridad de 0.6124903919258758 para 18 tweets.\n",
      "292. Adajosefina12 con una similaridad de 0.6120565240182464 para 11 tweets.\n",
      "293. baranaoa con una similaridad de 0.6120565240182464 para 11 tweets.\n",
      "294. orlandoelgueta con una similaridad de 0.6120565240182464 para 11 tweets.\n",
      "295. Curico1180 con una similaridad de 0.6120565240182464 para 11 tweets.\n",
      "296. Christo51355527 con una similaridad de 0.6120565240182464 para 11 tweets.\n",
      "297. JmsJanis con una similaridad de 0.6107444491614636 para 17 tweets.\n",
      "298. Cmariamoya con una similaridad de 0.6103199174406605 para 17 tweets.\n",
      "299. fcojfs con una similaridad de 0.6100041217688277 para 18 tweets.\n",
      "300. elpiloto767 con una similaridad de 0.6086579775655407 para 18 tweets.\n",
      "301. Patrici08866230 con una similaridad de 0.6079853479853479 para 10 tweets.\n",
      "302. pesegosa con una similaridad de 0.6074885898415313 para 22 tweets.\n",
      "303. Coke19701 con una similaridad de 0.60611971136819 para 58 tweets.\n",
      "304. LorenElen con una similaridad de 0.601644819826638 para 22 tweets.\n",
      "305. REALIDA67110571 con una similaridad de 0.6011485042735043 para 12 tweets.\n",
      "306. Silvest12665481 con una similaridad de 0.6010554878975932 para 37 tweets.\n",
      "307. Viejopascueroo con una similaridad de 0.5995564892623715 para 18 tweets.\n",
      "308. ladobskur con una similaridad de 0.5995564892623715 para 18 tweets.\n",
      "309. bello_girasol con una similaridad de 0.5991789747141966 para 149 tweets.\n",
      "310. RicardoTB38 con una similaridad de 0.5990450571100726 para 30 tweets.\n",
      "311. vmvn1977 con una similaridad de 0.5984615384615385 para 10 tweets.\n",
      "312. rsalinash con una similaridad de 0.5984615384615385 para 10 tweets.\n",
      "313. ArrauIrene con una similaridad de 0.5984615384615385 para 10 tweets.\n",
      "314. marcelo37450963 con una similaridad de 0.5984615384615385 para 10 tweets.\n",
      "315. gito23 con una similaridad de 0.5984615384615384 para 10 tweets.\n",
      "316. OnacuaraRotinom con una similaridad de 0.5984615384615384 para 10 tweets.\n",
      "317. Capitanleviack1 con una similaridad de 0.5984615384615384 para 10 tweets.\n",
      "318. clauherrerao con una similaridad de 0.5970862470862471 para 11 tweets.\n",
      "319. Camilav91121567 con una similaridad de 0.597086247086247 para 11 tweets.\n",
      "320. GermanWolfs con una similaridad de 0.5970766413074106 para 13 tweets.\n",
      "321. MardonesPantoj1 con una similaridad de 0.5968915343915345 para 12 tweets.\n",
      "322. p8k82014 con una similaridad de 0.5968751648841477 para 71 tweets.\n",
      "323. MonicaNegrin con una similaridad de 0.5966225071633402 para 149 tweets.\n",
      "324. negrot8 con una similaridad de 0.596538365606239 para 65 tweets.\n",
      "325. pichi78177903 con una similaridad de 0.595633482408346 para 419 tweets.\n",
      "326. juanenriquepena con una similaridad de 0.5956043956043956 para 23 tweets.\n",
      "327. kanuto1970 con una similaridad de 0.5955959164292497 para 18 tweets.\n",
      "328. Rodrigovega12 con una similaridad de 0.5951001896654072 para 28 tweets.\n",
      "329. Maraboli65 con una similaridad de 0.5950021006472618 para 18 tweets.\n",
      "330. normagallardop con una similaridad de 0.5938013136289 para 29 tweets.\n",
      "331. unda_rolando con una similaridad de 0.5932846262911623 para 54 tweets.\n",
      "332. Ramirez_JI1970 con una similaridad de 0.5929185311456782 para 19 tweets.\n",
      "333. alex47827557 con una similaridad de 0.5924068552152042 para 31 tweets.\n",
      "334. Mr_Zapata con una similaridad de 0.5922405073140365 para 30 tweets.\n",
      "335. fabianfelipe88 con una similaridad de 0.592203788456649 para 23 tweets.\n",
      "336. Rou08517226 con una similaridad de 0.591181857358328 para 17 tweets.\n",
      "337. nycomvv con una similaridad de 0.5906157556716178 para 23 tweets.\n",
      "338. Verodmj2012 con una similaridad de 0.5904761904761905 para 10 tweets.\n",
      "339. Marce79680515 con una similaridad de 0.5901282051282052 para 10 tweets.\n",
      "340. CherreraClaudia con una similaridad de 0.5901282051282052 para 10 tweets.\n",
      "341. EmilioC29716725 con una similaridad de 0.5899766899766901 para 11 tweets.\n",
      "342. FrancoxChile con una similaridad de 0.5899766899766901 para 11 tweets.\n",
      "343. mercceccorj con una similaridad de 0.5899766899766901 para 11 tweets.\n",
      "344. aleitapatriota con una similaridad de 0.5897385768353511 para 22 tweets.\n",
      "345. maca_ugarte3 con una similaridad de 0.5893777248354299 para 68 tweets.\n",
      "346. Claudi0Mun0z con una similaridad de 0.5891569215098627 para 34 tweets.\n",
      "347. killemall1976 con una similaridad de 0.5889570740576934 para 19 tweets.\n",
      "348. ggacdc2022 con una similaridad de 0.5888775163700201 para 23 tweets.\n",
      "349. AvloJego con una similaridad de 0.5882051282051282 para 10 tweets.\n",
      "350. centro_extreme con una similaridad de 0.5882051282051282 para 10 tweets.\n",
      "351. claudialenta con una similaridad de 0.5882051282051282 para 10 tweets.\n",
      "352. trebol_house con una similaridad de 0.5881415969651265 para 24 tweets.\n",
      "353. SolevelynOyarzo con una similaridad de 0.587883089133089 para 30 tweets.\n",
      "354. Danielito_rodan con una similaridad de 0.58754052460949 para 29 tweets.\n",
      "355. claud_00 con una similaridad de 0.5866769565104438 para 45 tweets.\n",
      "356. elpedrochamorro con una similaridad de 0.5865462476332037 para 45 tweets.\n",
      "357. Elisavinu con una similaridad de 0.586104826546003 para 17 tweets.\n",
      "358. Guiller66887019 con una similaridad de 0.5855555872424383 para 34 tweets.\n",
      "359. lautarop con una similaridad de 0.5849995723841724 para 166 tweets.\n",
      "360. ccavallo1 con una similaridad de 0.5846438814288303 para 13 tweets.\n",
      "361. sandra_vasquez con una similaridad de 0.5844931413042869 para 24 tweets.\n",
      "362. MARTYU12469305 con una similaridad de 0.5843489843489844 para 11 tweets.\n",
      "363. Chilenoapie2249 con una similaridad de 0.5841098023121433 para 130 tweets.\n",
      "364. LuisOrtegaCaro con una similaridad de 0.5832912233863791 para 17 tweets.\n",
      "365. gracielasmz con una similaridad de 0.583158263305322 para 16 tweets.\n",
      "366. tuiterlectura1 con una similaridad de 0.5818851470167259 para 12 tweets.\n",
      "367. clrojasg con una similaridad de 0.5818779804073922 para 12 tweets.\n",
      "368. Tami63352039 con una similaridad de 0.5816847572362275 para 48 tweets.\n",
      "369. Ana14921882 con una similaridad de 0.5812665343915343 para 12 tweets.\n",
      "370. MRALEX26967082 con una similaridad de 0.5812665343915343 para 12 tweets.\n",
      "371. Argonauta_1965 con una similaridad de 0.5812665343915343 para 12 tweets.\n",
      "372. acont77 con una similaridad de 0.5812665343915343 para 12 tweets.\n",
      "373. EstelaM36547846 con una similaridad de 0.5810071507439929 para 18 tweets.\n",
      "374. gente_sur_cl con una similaridad de 0.580283189946019 para 32 tweets.\n",
      "375. Camilo23935957 con una similaridad de 0.5802040777951356 para 245 tweets.\n",
      "376. rodjaramillo con una similaridad de 0.57991452991453 para 24 tweets.\n",
      "377. piedelimon33 con una similaridad de 0.5798726328138093 para 12 tweets.\n",
      "378. gigimarinakis con una similaridad de 0.5798319327731093 para 11 tweets.\n",
      "379. viceduar64 con una similaridad de 0.5794364065520456 para 237 tweets.\n",
      "380. kmagato con una similaridad de 0.5793684303752041 para 19 tweets.\n",
      "381. telmapilar con una similaridad de 0.579176189706652 para 28 tweets.\n",
      "382. adolfoarias7 con una similaridad de 0.5786879786879785 para 11 tweets.\n",
      "383. BeatrizVela13 con una similaridad de 0.5783456989453991 para 28 tweets.\n",
      "384. PepeOrtegaJim1 con una similaridad de 0.5778315956012033 para 18 tweets.\n",
      "385. Oerip42531163 con una similaridad de 0.5778315956012032 para 18 tweets.\n",
      "386. AleFigueroa81 con una similaridad de 0.5777697296140756 para 76 tweets.\n",
      "387. AlexDeLargeCHI con una similaridad de 0.5771019593270234 para 12 tweets.\n",
      "388. pacita1976 con una similaridad de 0.5770916281785846 para 23 tweets.\n",
      "389. JCCONTACTOSUR con una similaridad de 0.5765723656935378 para 708 tweets.\n",
      "390. alexheli_i con una similaridad de 0.5763305322128851 para 17 tweets.\n",
      "391. elmosquitocl con una similaridad de 0.5762930544907287 para 52 tweets.\n",
      "392. Pame4378 con una similaridad de 0.5762393162393161 para 10 tweets.\n",
      "393. evamonicalb con una similaridad de 0.5762393162393161 para 10 tweets.\n",
      "394. pilgrimfrags con una similaridad de 0.5762393162393161 para 10 tweets.\n",
      "395. RoroPerez15 con una similaridad de 0.5755374510546926 para 19 tweets.\n",
      "396. Patriot_1973 con una similaridad de 0.5747390175961605 para 21 tweets.\n",
      "397. AronCon92533296 con una similaridad de 0.5745391239720165 para 23 tweets.\n",
      "398. Numir con una similaridad de 0.5733751097387461 para 11 tweets.\n",
      "399. manevergara con una similaridad de 0.5733751097387461 para 11 tweets.\n",
      "400. Alejand53784318 con una similaridad de 0.5733751097387461 para 11 tweets.\n",
      "401. doris53859741 con una similaridad de 0.5733751097387461 para 11 tweets.\n",
      "402. tapia1952 con una similaridad de 0.5733751097387461 para 11 tweets.\n",
      "403. Liberta64239827 con una similaridad de 0.5733751097387461 para 11 tweets.\n",
      "404. CapIvansotomuni con una similaridad de 0.5730901282625419 para 11 tweets.\n",
      "405. Vegeta_Gasp con una similaridad de 0.5727640780272361 para 11 tweets.\n",
      "406. SergioP88693823 con una similaridad de 0.5727640780272358 para 11 tweets.\n",
      "407. FelipeS46509376 con una similaridad de 0.5723993936976474 para 46 tweets.\n",
      "408. Juno54807318 con una similaridad de 0.572179550553253 para 17 tweets.\n",
      "409. DanielAquilesR7 con una similaridad de 0.5709617180205416 para 60 tweets.\n",
      "410. sandrac0609 con una similaridad de 0.5709617180205416 para 12 tweets.\n",
      "411. vaneotth con una similaridad de 0.5709617180205416 para 12 tweets.\n",
      "412. will_297 con una similaridad de 0.5709617180205416 para 12 tweets.\n",
      "413. LolitaQueenNice con una similaridad de 0.5709617180205416 para 12 tweets.\n",
      "414. JotaJanna con una similaridad de 0.5709617180205416 para 12 tweets.\n",
      "415. Beatrizoya40 con una similaridad de 0.5709617180205416 para 12 tweets.\n",
      "416. pamelaandreaqui con una similaridad de 0.5709617180205416 para 12 tweets.\n",
      "417. Nancynicole3 con una similaridad de 0.5709617180205416 para 12 tweets.\n",
      "418. Ruthpal20320157 con una similaridad de 0.5709617180205416 para 12 tweets.\n",
      "419. Mapi67744105 con una similaridad de 0.5709617180205416 para 12 tweets.\n",
      "420. JuanaVergaraMu1 con una similaridad de 0.5709617180205414 para 18 tweets.\n",
      "421. andresirazabal6 con una similaridad de 0.5709617180205412 para 24 tweets.\n",
      "422. fran8384 con una similaridad de 0.5709617180205412 para 24 tweets.\n",
      "423. Arcel_Adio con una similaridad de 0.5706431762681763 para 10 tweets.\n",
      "424. ti77a con una similaridad de 0.5706052461470419 para 16 tweets.\n",
      "425. renemunozescud1 con una similaridad de 0.5692640692640693 para 11 tweets.\n",
      "426. Dany_malvada con una similaridad de 0.5691334083490945 para 21 tweets.\n",
      "427. andres_gamboa_ con una similaridad de 0.5688493324856961 para 11 tweets.\n",
      "428. DoloresLuzz con una similaridad de 0.5688492063492062 para 12 tweets.\n",
      "429. Seven7778149172 con una similaridad de 0.5688492063492062 para 12 tweets.\n",
      "430. nonogonzalez56 con una similaridad de 0.5686021956760849 para 90 tweets.\n",
      "431. GloriaLopezflo3 con una similaridad de 0.5683808881177304 para 18 tweets.\n",
      "432. XimenaXimepjm con una similaridad de 0.568149949313076 para 46 tweets.\n",
      "433. luisver07450499 con una similaridad de 0.5679206234512094 para 174 tweets.\n",
      "434. VictorM51993142 con una similaridad de 0.5672597244025817 para 21 tweets.\n",
      "435. CHOPERCHUMANGO con una similaridad de 0.5667832167832167 para 11 tweets.\n",
      "436. Pato93979823 con una similaridad de 0.5666081157309227 para 27 tweets.\n",
      "437. PiPeAlT con una similaridad de 0.5660889355742296 para 16 tweets.\n",
      "438. Schneid54840737 con una similaridad de 0.5658322784875581 para 28 tweets.\n",
      "439. Royarzun1974 con una similaridad de 0.5655552391078703 para 60 tweets.\n",
      "440. Russ31058627 con una similaridad de 0.5653297088573859 para 29 tweets.\n",
      "441. cami_mundaca con una similaridad de 0.5652958152958152 para 11 tweets.\n",
      "442. marilu19591 con una similaridad de 0.5652958152958152 para 11 tweets.\n",
      "443. luisdelaoctava8 con una similaridad de 0.565128205128205 para 10 tweets.\n",
      "444. josplit1 con una similaridad de 0.565128205128205 para 10 tweets.\n",
      "445. MacaSimplemente con una similaridad de 0.565015625568985 para 44 tweets.\n",
      "446. Ivan_patriotaCh con una similaridad de 0.5642891509710731 para 30 tweets.\n",
      "447. cheGuevadas con una similaridad de 0.5640141283063245 para 18 tweets.\n",
      "448. pedrepablo con una similaridad de 0.56305121778806 para 15 tweets.\n",
      "449. piolinsting con una similaridad de 0.5630512177880599 para 15 tweets.\n",
      "450. EduSotoA con una similaridad de 0.5626843845072343 para 19 tweets.\n",
      "451. AuroraNovoa8 con una similaridad de 0.5622510822510822 para 11 tweets.\n",
      "452. kepler33i con una similaridad de 0.5621460599389292 para 19 tweets.\n",
      "453. Cfpoblete1 con una similaridad de 0.5620039682539683 para 16 tweets.\n",
      "454. carlosedodiaz con una similaridad de 0.5620039682539681 para 16 tweets.\n",
      "455. reinosogra con una similaridad de 0.5620039682539681 para 16 tweets.\n",
      "456. bartolitomas85 con una similaridad de 0.5617965367965367 para 11 tweets.\n",
      "457. Lalo5565 con una similaridad de 0.5616339542810131 para 16 tweets.\n",
      "458. Francis23541005 con una similaridad de 0.5611373211411912 para 28 tweets.\n",
      "459. RamonSe197 con una similaridad de 0.56109124401429 para 73 tweets.\n",
      "460. llitovelas con una similaridad de 0.5610000757059577 para 37 tweets.\n",
      "461. r_briceno con una similaridad de 0.5607834597253536 para 41 tweets.\n",
      "462. oskratos con una similaridad de 0.5607778408932182 para 23 tweets.\n",
      "463. LuisHuertaPonc con una similaridad de 0.560471910336041 para 24 tweets.\n",
      "464. juanriv42678873 con una similaridad de 0.5603663003663003 para 10 tweets.\n",
      "465. Patrici26610281 con una similaridad de 0.5603663003663003 para 10 tweets.\n",
      "466. en_iquique con una similaridad de 0.5603482546864897 para 40 tweets.\n",
      "467. Felipe72878681 con una similaridad de 0.5598023504273505 para 16 tweets.\n",
      "468. Franco67560799 con una similaridad de 0.5596917966423357 para 81 tweets.\n",
      "469. marcoso1975 con una similaridad de 0.5594627594627595 para 12 tweets.\n",
      "470. Nadieporahora17 con una similaridad de 0.5594627594627595 para 12 tweets.\n",
      "471. UcBabilonia con una similaridad de 0.5594501268660139 para 13 tweets.\n",
      "472. Zuni88169716 con una similaridad de 0.5591635985497877 para 16 tweets.\n",
      "473. victorpolo11 con una similaridad de 0.55873778998779 para 12 tweets.\n",
      "474. IvisPedza con una similaridad de 0.5587377899877899 para 12 tweets.\n",
      "475. MarcosBeltranm con una similaridad de 0.5574592074592075 para 11 tweets.\n",
      "476. JudithRogozins1 con una similaridad de 0.5573879413698422 para 65 tweets.\n",
      "477. MnicaYolivalzu con una similaridad de 0.5569697480881692 para 16 tweets.\n",
      "478. giovann15612630 con una similaridad de 0.5564865689865691 para 12 tweets.\n",
      "479. delkatamatun con una similaridad de 0.5563460325650729 para 24 tweets.\n",
      "480. selloffice con una similaridad de 0.556037296037296 para 10 tweets.\n",
      "481. Micaela41377582 con una similaridad de 0.556037296037296 para 10 tweets.\n",
      "482. NicoUlloa77 con una similaridad de 0.556037296037296 para 10 tweets.\n",
      "483. DiegoMo63329388 con una similaridad de 0.556037296037296 para 10 tweets.\n",
      "484. mparracgmailcom con una similaridad de 0.556037296037296 para 10 tweets.\n",
      "485. Sra_BanChu con una similaridad de 0.5559486952675806 para 19 tweets.\n",
      "486. franmunozb con una similaridad de 0.5556118646288924 para 12 tweets.\n",
      "487. CompaniaLetras con una similaridad de 0.5554195804195804 para 11 tweets.\n",
      "488. manumartinez51 con una similaridad de 0.5554195804195804 para 11 tweets.\n",
      "489. A_Codocedo con una similaridad de 0.5549275375027768 para 17 tweets.\n",
      "490. pabllanq con una similaridad de 0.554898963418269 para 102 tweets.\n",
      "491. ManriquezNeira con una similaridad de 0.5545978512068477 para 17 tweets.\n",
      "492. mvvb21 con una similaridad de 0.5544783537264742 para 28 tweets.\n",
      "493. Gustavo28586960 con una similaridad de 0.5541405962458593 para 12 tweets.\n",
      "494. OlivaresHeredia con una similaridad de 0.5540903540903541 para 21 tweets.\n",
      "495. prinspamela con una similaridad de 0.5533721180780006 para 28 tweets.\n",
      "496. Pab47807820Juan con una similaridad de 0.5527956513675076 para 19 tweets.\n",
      "497. _SrPerez con una similaridad de 0.5527041084438716 para 13 tweets.\n",
      "498. JosMiguelChCas1 con una similaridad de 0.5521624379535744 para 78 tweets.\n",
      "499. Santiag75051265 con una similaridad de 0.5520847268673357 para 10 tweets.\n",
      "500. MariaPazBusta11 con una similaridad de 0.5520847268673357 para 10 tweets.\n",
      "501. 88VaeVictis con una similaridad de 0.5520847268673357 para 10 tweets.\n",
      "502. Nicolito77 con una similaridad de 0.5520847268673357 para 10 tweets.\n",
      "503. LitoMendez12 con una similaridad de 0.5520847268673357 para 10 tweets.\n",
      "504. claudiosilva67 con una similaridad de 0.5520847268673357 para 10 tweets.\n",
      "505. ErikLloel con una similaridad de 0.5516934046345812 para 17 tweets.\n",
      "506. abue15682934 con una similaridad de 0.5516138763197587 para 11 tweets.\n",
      "507. rguinezl1 con una similaridad de 0.5513766305814989 para 25 tweets.\n",
      "508. Danielsdanfran1 con una similaridad de 0.5501121270926407 para 17 tweets.\n",
      "509. mmadariaga1959 con una similaridad de 0.5492368243593735 para 18 tweets.\n",
      "510. FrancoA86436267 con una similaridad de 0.5490450695328298 para 28 tweets.\n",
      "511. gabrielaza649 con una similaridad de 0.548903375344053 para 59 tweets.\n",
      "512. Lahoradelleon1 con una similaridad de 0.5488432620011566 para 12 tweets.\n",
      "513. Salas_Fdo con una similaridad de 0.54882317864534 para 11 tweets.\n",
      "514. pabloca33948224 con una similaridad de 0.5487565087494058 para 47 tweets.\n",
      "515. ElianaParraM8 con una similaridad de 0.5486044719310439 para 11 tweets.\n",
      "516. JuanAndia19 con una similaridad de 0.5485799224929658 para 12 tweets.\n",
      "517. ManuelBecerra con una similaridad de 0.5484615384615384 para 10 tweets.\n",
      "518. Alejand11218081 con una similaridad de 0.5484615384615384 para 10 tweets.\n",
      "519. pachy12157345 con una similaridad de 0.5484615384615383 para 10 tweets.\n",
      "520. Tedlamorna con una similaridad de 0.5484615384615383 para 10 tweets.\n",
      "521. jgvosanh con una similaridad de 0.5484615384615383 para 10 tweets.\n",
      "522. Edito53077564 con una similaridad de 0.5484615384615383 para 10 tweets.\n",
      "523. Chileno8CH8 con una similaridad de 0.5474378093995319 para 11 tweets.\n",
      "524. botdde con una similaridad de 0.5474010837647201 para 11 tweets.\n",
      "525. FranciscaZika1 con una similaridad de 0.5471492275840102 para 16 tweets.\n",
      "526. Chopan_Chile con una similaridad de 0.5469073498964803 para 16 tweets.\n",
      "527. Raulxxx8 con una similaridad de 0.5466065126785824 para 94 tweets.\n",
      "528. octavo_del con una similaridad de 0.5453129307968018 para 12 tweets.\n",
      "529. MiguelO81244513 con una similaridad de 0.5447840354090356 para 28 tweets.\n",
      "530. yamilsabra con una similaridad de 0.5446414696414695 para 12 tweets.\n",
      "531. GerardoCamino8 con una similaridad de 0.5441356029591324 para 13 tweets.\n",
      "532. RosaMartel10 con una similaridad de 0.5441176470588234 para 17 tweets.\n",
      "533. alecruzdelsur con una similaridad de 0.5440167256328062 para 23 tweets.\n",
      "534. Reinald75391143 con una similaridad de 0.5434146559159695 para 26 tweets.\n",
      "535. Cristia66581780 con una similaridad de 0.5423883535338642 para 36 tweets.\n",
      "536. MiguelB15680147 con una similaridad de 0.5420470663602786 para 159 tweets.\n",
      "537. InciyHan con una similaridad de 0.5419146825396824 para 12 tweets.\n",
      "538. DEGG19821 con una similaridad de 0.5419146825396824 para 12 tweets.\n",
      "539. Tavuxxo con una similaridad de 0.5412316441728205 para 11 tweets.\n",
      "540. Rcanario74 con una similaridad de 0.5411700580336191 para 31 tweets.\n",
      "541. palidez1 con una similaridad de 0.5404273504273508 para 15 tweets.\n",
      "542. pitflow con una similaridad de 0.540186722330579 para 44 tweets.\n",
      "543. Chilena201 con una similaridad de 0.53981419849281 para 11 tweets.\n",
      "544. mlhomecoating con una similaridad de 0.5395763656633222 para 11 tweets.\n",
      "545. mocambo_el con una similaridad de 0.5395166237271499 para 11 tweets.\n",
      "546. ItaloGenovese1 con una similaridad de 0.5395166237271499 para 11 tweets.\n",
      "547. NeasmicJuan con una similaridad de 0.5395166237271499 para 11 tweets.\n",
      "548. PolyToro con una similaridad de 0.5395166237271499 para 11 tweets.\n",
      "549. ja_yanez con una similaridad de 0.5394132054412786 para 19 tweets.\n",
      "550. domingue_zambra con una similaridad de 0.5390892225154351 para 36 tweets.\n",
      "551. MaraFer90565327 con una similaridad de 0.5383743775287892 para 12 tweets.\n",
      "552. Fernand75437206 con una similaridad de 0.5383743775287892 para 12 tweets.\n",
      "553. elderechista21 con una similaridad de 0.5383743775287892 para 12 tweets.\n",
      "554. RosaritoCz con una similaridad de 0.5383743775287891 para 12 tweets.\n",
      "555. CristbalElguet3 con una similaridad de 0.5383743775287891 para 12 tweets.\n",
      "556. chocheandres13 con una similaridad de 0.5383743775287891 para 12 tweets.\n",
      "557. salomon66330386 con una similaridad de 0.5381954873399101 para 37 tweets.\n",
      "558. Magallanico7713 con una similaridad de 0.5373770020828844 para 34 tweets.\n",
      "559. Soledad35667069 con una similaridad de 0.536007409029393 para 34 tweets.\n",
      "560. Crustian13 con una similaridad de 0.5360007639419403 para 22 tweets.\n",
      "561. arielrfx con una similaridad de 0.5355275443510737 para 17 tweets.\n",
      "562. 5_leigh con una similaridad de 0.5348141366717217 para 28 tweets.\n",
      "563. jz1972 con una similaridad de 0.5340212751767371 para 35 tweets.\n",
      "564. LiaoKeku con una similaridad de 0.5339549339549339 para 11 tweets.\n",
      "565. CS02810743 con una similaridad de 0.5337021765227827 para 35 tweets.\n",
      "566. Rod12112021 con una similaridad de 0.5336913267947747 para 37 tweets.\n",
      "567. ConsejeroEsotr1 con una similaridad de 0.5324795635980488 para 34 tweets.\n",
      "568. aeramos1980 con una similaridad de 0.5324675324675326 para 11 tweets.\n",
      "569. Mauro_Flaquer con una similaridad de 0.5324675324675326 para 11 tweets.\n",
      "570. cretamal1300 con una similaridad de 0.5324675324675325 para 11 tweets.\n",
      "571. BeniVal5 con una similaridad de 0.5324675324675325 para 11 tweets.\n",
      "572. pensador1983 con una similaridad de 0.5320816343066146 para 231 tweets.\n",
      "573. psanhuezah con una similaridad de 0.5320162207933108 para 17 tweets.\n",
      "574. America25144564 con una similaridad de 0.5318189775910364 para 16 tweets.\n",
      "575. Pmendez323Pablo con una similaridad de 0.5314938973994701 para 19 tweets.\n",
      "576. Fernand19234801 con una similaridad de 0.5300453514739231 para 21 tweets.\n",
      "577. AJequier con una similaridad de 0.5292939869830058 para 122 tweets.\n",
      "578. jorgeed26794627 con una similaridad de 0.5286084136286566 para 13 tweets.\n",
      "579. PasteneHernan con una similaridad de 0.5284798534798534 para 12 tweets.\n",
      "580. huarasina2011 con una similaridad de 0.5278369099693159 para 73 tweets.\n",
      "581. Kinya2022 con una similaridad de 0.5277565571683217 para 22 tweets.\n",
      "582. Crlockman con una similaridad de 0.5275297619047619 para 16 tweets.\n",
      "583. Micaela05012005 con una similaridad de 0.5269430552247886 para 48 tweets.\n",
      "584. Patrici49855590 con una similaridad de 0.5263098069756419 para 28 tweets.\n",
      "585. cannond51105573 con una similaridad de 0.5254700854700856 para 11 tweets.\n",
      "586. Walteriopalaci2 con una similaridad de 0.5254700854700856 para 11 tweets.\n",
      "587. Lepatoss1 con una similaridad de 0.5254700854700856 para 11 tweets.\n",
      "588. coneguerra83 con una similaridad de 0.5254635487744209 para 17 tweets.\n",
      "589. tortusmil con una similaridad de 0.5248533922218133 para 11 tweets.\n",
      "590. totorockdj con una similaridad de 0.5247267223660415 para 23 tweets.\n",
      "591. marta_lea1 con una similaridad de 0.52407384799888 para 24 tweets.\n",
      "592. mirkovon con una similaridad de 0.5238539238539238 para 11 tweets.\n",
      "593. FachaPobre5 con una similaridad de 0.5232763559969442 para 22 tweets.\n",
      "594. ceciliadcaq con una similaridad de 0.5231513278388281 para 32 tweets.\n",
      "595. Boris__Cl con una similaridad de 0.5230628052503052 para 40 tweets.\n",
      "596. IndependienteTi con una similaridad de 0.5230391830391832 para 15 tweets.\n",
      "597. Chelovdr77 con una similaridad de 0.5221261194945405 para 11 tweets.\n",
      "598. jairo_varas con una similaridad de 0.5219554775181899 para 96 tweets.\n",
      "599. CDiagin con una similaridad de 0.5215054918288385 para 28 tweets.\n",
      "600. csaez0 con una similaridad de 0.5210955009329624 para 60 tweets.\n",
      "601. ricardorohe con una similaridad de 0.5203778677462888 para 11 tweets.\n",
      "602. luisadgallardo con una similaridad de 0.5203778677462888 para 11 tweets.\n",
      "603. Worges con una similaridad de 0.5203495378006127 para 34 tweets.\n",
      "604. julioro79328136 con una similaridad de 0.5203349204787832 para 138 tweets.\n",
      "605. JavierFG_ con una similaridad de 0.5202912832318642 para 52 tweets.\n",
      "606. Veronica2680 con una similaridad de 0.5202310606749928 para 72 tweets.\n",
      "607. PedroDeValdiv14 con una similaridad de 0.5201694021030911 para 53 tweets.\n",
      "608. LORETOVALDIVIA9 con una similaridad de 0.5195970695970697 para 26 tweets.\n",
      "609. MariaMcszoiza con una similaridad de 0.5194513260037454 para 36 tweets.\n",
      "610. JuanPab83662918 con una similaridad de 0.5190756853639552 para 27 tweets.\n",
      "611. clabarra01 con una similaridad de 0.5189696096030452 para 95 tweets.\n",
      "612. AlexVarUC con una similaridad de 0.5187512970121664 para 18 tweets.\n",
      "613. Edwards32237132 con una similaridad de 0.5187246050732892 para 16 tweets.\n",
      "614. lulumuzard con una similaridad de 0.5185710508253031 para 43 tweets.\n",
      "615. marcelo88406806 con una similaridad de 0.5182814513765369 para 28 tweets.\n",
      "616. Olafoazul con una similaridad de 0.5181320735769512 para 40 tweets.\n",
      "617. soldadito1951 con una similaridad de 0.5180236141352628 para 40 tweets.\n",
      "618. araucanoXD con una similaridad de 0.5175894879695835 para 107 tweets.\n",
      "619. Lxsarbxolxspun1 con una similaridad de 0.517459120400297 para 21 tweets.\n",
      "620. seba7gonzalez con una similaridad de 0.5174521658896659 para 12 tweets.\n",
      "621. leticiatru con una similaridad de 0.5172402159244266 para 32 tweets.\n",
      "622. Jaloys con una similaridad de 0.5172085879806467 para 16 tweets.\n",
      "623. randomcuenta5 con una similaridad de 0.5165497318962665 para 12 tweets.\n",
      "624. Efrain188954 con una similaridad de 0.5158737164458768 para 65 tweets.\n",
      "625. erlamellado con una similaridad de 0.5153846153846153 para 14 tweets.\n",
      "626. GenzJosefa con una similaridad de 0.5152180286649756 para 38 tweets.\n",
      "627. EstebanLander1 con una similaridad de 0.5149973865144143 para 22 tweets.\n",
      "628. CuchufliB con una similaridad de 0.5149052352953062 para 12 tweets.\n",
      "629. ciberdine2012 con una similaridad de 0.5148359653458906 para 17 tweets.\n",
      "630. quilpue9 con una similaridad de 0.5137232659368254 para 122 tweets.\n",
      "631. _renzuc con una similaridad de 0.5135602785014551 para 25 tweets.\n",
      "632. Hernandezabog con una similaridad de 0.513277980189745 para 13 tweets.\n",
      "633. kingdeespana con una similaridad de 0.5131849053724055 para 32 tweets.\n",
      "634. FemuvielMunoz con una similaridad de 0.5130704755487662 para 41 tweets.\n",
      "635. alecontreXXI con una similaridad de 0.5127197077661473 para 12 tweets.\n",
      "636. IdeNatacha con una similaridad de 0.5124652214816148 para 61 tweets.\n",
      "637. Lagp70 con una similaridad de 0.5116946778711484 para 10 tweets.\n",
      "638. gonzalo_cu con una similaridad de 0.5116946778711484 para 10 tweets.\n",
      "639. carlaramu con una similaridad de 0.5116946778711484 para 10 tweets.\n",
      "640. Pat_Guerram con una similaridad de 0.5116946778711484 para 10 tweets.\n",
      "641. LorenaA81841111 con una similaridad de 0.5116946778711484 para 10 tweets.\n",
      "642. AntiMechero2020 con una similaridad de 0.5116946778711484 para 10 tweets.\n",
      "643. VeronicaNune1 con una similaridad de 0.5116946778711484 para 10 tweets.\n",
      "644. aelguetat con una similaridad de 0.5105844969566774 para 12 tweets.\n",
      "645. Rene98572145 con una similaridad de 0.5104761904761903 para 10 tweets.\n",
      "646. SONNYCO19902370 con una similaridad de 0.5104088175231106 para 18 tweets.\n",
      "647. Luk_GG4eter con una similaridad de 0.5095701461010386 para 25 tweets.\n",
      "648. pati_guzman_g con una similaridad de 0.5094793125583565 para 16 tweets.\n",
      "649. Marciac_ale con una similaridad de 0.509102107779684 para 70 tweets.\n",
      "650. JPaulo48707017 con una similaridad de 0.5088981531289224 para 13 tweets.\n",
      "651. ChilenosAtentos con una similaridad de 0.5087563951200313 para 11 tweets.\n",
      "652. camilor32968098 con una similaridad de 0.5087563951200313 para 11 tweets.\n",
      "653. FontalEduardo1 con una similaridad de 0.5087563951200313 para 11 tweets.\n",
      "654. JuanPinochet12 con una similaridad de 0.5082365628610026 para 27 tweets.\n",
      "655. MateolivaOliva con una similaridad de 0.5079885201944027 para 45 tweets.\n",
      "656. RicardoChaiten con una similaridad de 0.5079772079772079 para 12 tweets.\n",
      "657. MariavivianavT con una similaridad de 0.5072869909090985 para 215 tweets.\n",
      "658. MTITOMendoza con una similaridad de 0.5072180865729253 para 15 tweets.\n",
      "659. Rawlpixel con una similaridad de 0.5071482439129499 para 17 tweets.\n",
      "660. Jescanillam con una similaridad de 0.5069539610716082 para 15 tweets.\n",
      "661. CarmenGloriaSal con una similaridad de 0.5066390192440611 para 21 tweets.\n",
      "662. PatriotaPatito con una similaridad de 0.5060900627941408 para 219 tweets.\n",
      "663. UgoL20797528 con una similaridad de 0.5059401446254895 para 16 tweets.\n",
      "664. Luis63737593 con una similaridad de 0.5057870370370371 para 12 tweets.\n",
      "665. RaimundoRabah con una similaridad de 0.5057870370370371 para 12 tweets.\n",
      "666. AnaDS86705473 con una similaridad de 0.5057870370370371 para 12 tweets.\n",
      "667. MarceloLeone197 con una similaridad de 0.505787037037037 para 30 tweets.\n",
      "668. Charlygop88 con una similaridad de 0.5057870370370369 para 18 tweets.\n",
      "669. mcm2310 con una similaridad de 0.5057870370370369 para 18 tweets.\n",
      "670. cosaco2011 con una similaridad de 0.5057870370370369 para 18 tweets.\n",
      "671. LidiaMa70884573 con una similaridad de 0.5053943452380952 para 16 tweets.\n",
      "672. mdelriob con una similaridad de 0.505246728389143 para 38 tweets.\n",
      "673. Vctor_Manuel_C con una similaridad de 0.5051755706790031 para 23 tweets.\n",
      "674. SraPand65940895 con una similaridad de 0.5051587301587301 para 10 tweets.\n",
      "675. ojo_de_horus10 con una similaridad de 0.5051587301587301 para 10 tweets.\n",
      "676. Christi43606398 con una similaridad de 0.5051587301587301 para 10 tweets.\n",
      "677. ghostgoya con una similaridad de 0.5051587301587301 para 10 tweets.\n",
      "678. Carmen_1984_ con una similaridad de 0.5051587301587301 para 10 tweets.\n",
      "679. maggiescobarC con una similaridad de 0.504810165280433 para 29 tweets.\n",
      "680. connection_r con una similaridad de 0.5045009814746656 para 16 tweets.\n",
      "681. Corvo_110973 con una similaridad de 0.5038084138084139 para 15 tweets.\n",
      "682. Verdugo9Elisa con una similaridad de 0.5037892934951758 para 18 tweets.\n",
      "683. oquirtcazor con una similaridad de 0.5026604973973395 para 14 tweets.\n",
      "684. segundo_ademir con una similaridad de 0.5023560014864361 para 15 tweets.\n",
      "685. VivaChileFree con una similaridad de 0.5020995082815738 para 32 tweets.\n",
      "686. bocondelnorte con una similaridad de 0.5020452354662882 para 35 tweets.\n",
      "687. lamoreno1949 con una similaridad de 0.5019714326989867 para 111 tweets.\n",
      "688. carmenchitita con una similaridad de 0.5018625416815463 para 13 tweets.\n",
      "689. miguelkant22 con una similaridad de 0.5015588851937536 para 32 tweets.\n",
      "690. Ciudadanolevi1 con una similaridad de 0.5015033466775121 para 13 tweets.\n",
      "691. BermedoPaola con una similaridad de 0.5014302021980509 para 23 tweets.\n",
      "692. Cesuribe con una similaridad de 0.5012641330176995 para 30 tweets.\n",
      "693. chilitohermoso con una similaridad de 0.5007306471306472 para 25 tweets.\n",
      "694. vivachilemialma con una similaridad de 0.5006737706737707 para 20 tweets.\n",
      "695. PipeTor93343568 con una similaridad de 0.5006463655492644 para 11 tweets.\n",
      "696. pablo_medina_ con una similaridad de 0.5006463655492644 para 11 tweets.\n",
      "697. DomingoETorres con una similaridad de 0.5001845043154711 para 38 tweets.\n"
     ]
    }
   ],
   "source": [
    "print_similar_users(user, users)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos el perfil del usuario con el que partimos y su usuario m√°s \"similar\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfil del Usuario rodrigoorellana\n",
      "Se pas√≥\n",
      "La burbuja de una convenci√≥n pueril, que divide y enfrenta‚Ä¶ #RechazoCrece\n",
      "El progrerio dando la cacha!\n",
      "Esto pasa por leer a Baradit\n",
      "Rechazo\n",
      "Todo tan chevere\n",
      "Humo t√≥xico por ac√°\n",
      "Por eso Rechazo\n",
      "Rechaza para no dar la cacha!\n",
      "La letra chica: no eres propietario‚Ä¶\n",
      "reciben lloriqueos\n",
      "Rechazo\n",
      "Avanza para ser rechazada üí™\n",
      "Humo\n",
      "Rechazo\n",
      "Matinales tomando nota para defensa del apruebo. As√≠ nos vamos a la mierda‚Ä¶\n",
      "Har√°n la pega que la prensa de izquierda no quieren que sepas\n",
      "Finlandia\n",
      "Humo\n",
      "Humo\n",
      "Pasado a humo\n",
      "Rechazo\n",
      "La ceguera ideol√≥gica de la izquierda los hace ser sencillamente miserables.\n",
      "Pasamos de Finlandia a Espa√±a y la realidad que generaron ( y que rechazaremos) es la de Bolivia‚Ä¶ te pasaste!\n",
      "Con raz√≥n! Vomitas desinformaci√≥n!\n",
      "Atria te rechazo\n",
      "Termocefalo‚Ä¶ esa enfermedad la atender√°n por fonasa? ojal√° no se deba esperar un par de a√±os para ser tratada.\n",
      "Puro humo‚Ä¶ haciendo mierda la estabilidad del pa√≠s.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Perfil del Usuario jpkramer63\n",
      "Idiota\n",
      "Que gran desilusi√≥n. Te cre√≠a inteligente.\n",
      "La mayor deserci√≥n. Del Circo\n",
      "Mentiroso ü§•\n",
      "Falso es la encuesta y sesgados tus tuit\n",
      "Que viejo m√°s siniestro. Es el ide√≥logo. Barraza el ejecutor. Baradit y stingo  sus bufones.\n",
      "Pobre tipo. Debe ver gente muerta\n",
      "Vamos Bernardo. Mi voto para constituyente. Se nota que es valioso\n",
      "Grande Rocio discurso valiente en la constituyente\n",
      "B√°sico\n",
      "Escoba\n",
      "B√°sica y torpe\n",
      "Esta Sra se ve√≠a inteligente pero decepci√≥n. Muy limitada\n",
      "Sacar a mil\n",
      "Inapropiable que es eso.  Quien invierte si no tiene agua ???\n",
      "Retrocede\n",
      "Siniestro\n",
      "4 gatos  vendiendo humo\n",
      "Sirve como noble ??? Un completo mamaracho\n",
      "Agua para todos es decir para los compa√±eros en especial de la Mix\n",
      "Con raz√≥n escriben puras tonteras que fundir√°n a Chile\n",
      "Humo\n",
      "Para atr√°s\n",
      "Ni√±ita das conferencias con torpedo. Y eso que eres profecional.\n",
      "Uf te consideraba serio e inteligente pero al lado de Barraza. Fiel reflejo del comunismo mentiroso  buen viaje\n",
      "Un ladr√≥n usurpador.\n",
      "La desepcion y falso como sus Curas amigos   Este se√±or\n",
      "Aplicando la ley y no culpando a carabineros\n",
      "Idiota\n",
      "Como?? Subsidio con impuestos para que t√∫ y yo viajemos barato. Muy mal enfocada inversi√≥n y gasto\n",
      "Humo.\n",
      "Humo\n",
      "Y sin seguros no hay inversi√≥n\n",
      "Mentiroso\n",
      "Humo\n",
      "Humo o cantos de sirena  si prefieres\n",
      "Y tambi√©n a respirar y al sol de verano. Puro humo\n",
      "Humo\n",
      "Ja ja\n",
      "Y tus amigos del PS. Como salieron\n",
      "Es que no es plurinacional todav√≠a\n",
      "Deja de mentir eres la mayor decepci√≥n de los constituyentes  cre√≠amos que eras inteligente gran error\n",
      "Humo\n",
      "Avanza para atr√°s\n",
      "Ja ja. Narnia.\n",
      "Salen 400 mil bolivianos todos los a√±os de su pa√≠s para buscar pega\n",
      "D√≠a hist√≥rico\n",
      "Bien Bernardo un hombre con trayectoria y juicioso\n",
      "Y casi la nominan a premio Nobel. Cara est√° para presidenta de cuarto b√°sico\n",
      "Humo y anti chileno anti progreso\n",
      "Si ser√° la Sra Juanita. Que despelote estan proponiendo\n",
      "Ingenuo y Pavo\n",
      "Cabro mentiroso\n",
      "Le falta una tabla para el Puente parece\n",
      "Descubrieron la rueda.  Mejor vuelve al hospital o consultorio  ah√≠ si sabes\n",
      "As√≠ se ven los 440 art√≠culos\n",
      "Me imagino que con traducci√≥n simult√°nea\n",
      "Vieja ignorante y fresca\n",
      "Fresco\n",
      "No Es plata propia y no del estado como acostumbran los pol√≠ticos a regalar\n",
      "Lo lograron. Un fiasco\n",
      "Entonces debe ser el triple\n",
      "Siniestro mentiroso\n",
      "Agotados chucha que poco hicieron destruir es f√°cil construir te creo\n",
      "Y el resultado un desastre\n",
      "Uf el ramillete pobre\n",
      "La mayor decepci√≥n de los constituyentes.\n",
      "Ja ja  que b√°sico y mentiroso eres\n",
      "Gaspar como m√©dico podr√°s ser bueno pero como constituyente  nota 2 adem√°s muy mentiroso\n",
      "No te creo nada\n",
      "Humo\n",
      "Mayor√≠a de extrema izquierda y No representantes de pueblos.\n",
      "Inservible\n",
      "Es tu APV y casa üè†\n",
      "Ja ja. Mediocres\n",
      "Ya los vikingos fueron los culpables.\n",
      "La mayor desilusi√≥n de los constituyentes es usted Se√±ora.\n",
      "Ufff usted se ve√≠a serio y con conocimientos   Gran decepci√≥n pero no tanto como la Politzer\n",
      "Uf ojal√° sea igual como t√∫ amigos curas proteg√≠an a curas viejos pedofilos\n",
      "Fuera ustedes mejor.\n",
      "Otra mentira de ustedes sre Barraza\n",
      "Humo\n",
      "Que bueno\n",
      "Los 4 anti fant√°sticos\n",
      "Mediocre\n",
      "Dile a tus amigos de la iglesia que vendan sus propiedades y construyan y regalen no es que eran tan buenitos ....\n",
      "Humo y m√°s humo\n"
     ]
    }
   ],
   "source": [
    "show_similar_pair(user, list(users.keys())[0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
